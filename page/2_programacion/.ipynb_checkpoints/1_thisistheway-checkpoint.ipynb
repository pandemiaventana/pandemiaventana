{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Génesis\n",
    "\n",
    "---\n",
    "\n",
    ":::{figure-md} markdown-fig\n",
    "<img src=\"../../img/page/2_cover.png\">\n",
    "\n",
    "**Ilustración realizada por Bernardo Dinamarca**.\n",
    ":::\n",
    "\n",
    "¡Hola! Comenzar, en primer lugar, con que el presente notebook es la mejora del primero que realicé. La primera versión del código era repetitiva y por tanto, poco eficiente. Me digne a mejorarla y este fue el resultado (aún no me convence, pero es trabajo honesto). \n",
    "\n",
    "Esta versión está hecha con un poco más de conocimiento, aunque cabe recalcar, no soy un maestro de la programación, y estoy bastante distante de serlo. Me considero un sobreviviente, y un constante aprendiz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando paquetes\n",
    "\n",
    "---\n",
    "\n",
    "En Python, tenemos la posibilidad de importar librerías, que en estricto rigor, es código ya escrito por otras personas. Por tanto, simplifica nuestra tarea, y es perfectamente común trabajar con ellas. En este caso, utilizaremos las siguientes librerías:\n",
    "\n",
    "- Pandas (librería por especialidad de manipulación de datos). Permite leer y trabajar con distintos tipos de archivos.\n",
    "\n",
    ":::{figure-md} markdown-fig\n",
    "<img src=\"https://www.adictosaltrabajo.com/wp-content/uploads/2020/12/1200px-Pandas_logo.svg_.png\">\n",
    "\n",
    "**Logo de la librería <a href=\"https://pandas.pydata.org/\">Pandas</a>**.\n",
    ":::\n",
    "\n",
    "- Numpy (librería de álgebra que trabaja en conjunto con Pandas).\n",
    "\n",
    ":::{figure-md} markdown-fig\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/3/31/NumPy_logo_2020.svg/1280px-NumPy_logo_2020.svg.png\">\n",
    "\n",
    "**Logo de la librería <a href=\"https://numpy.org/\">Numpy</a>**.\n",
    ":::\n",
    "\n",
    "- Y otras varias de Python base.\n",
    "\n",
    "En el siguiente bloque de código (1), importaremos las librerías necesarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando paquetes\n",
    "\n",
    "### Librería de manipulación de datos \n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "### Librería de álgebra\n",
    "import numpy as np\n",
    "\n",
    "### Librerías para graficar\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib as mpl\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "### Customizamos para tener fondos transparentes con alta resolución\n",
    "mpl.rcParams['figure.dpi']= 300\n",
    "mpl.rc(\"savefig\", dpi=300)\n",
    "plt.rcParams.update({\n",
    "    \"figure.facecolor\":  (0.0, 0.0, 0.0, 0.0),\n",
    "    \"axes.facecolor\":    (0.0, 0.0, 0.0, 0.0),\n",
    "    \"savefig.facecolor\": (0.0, 0.0, 0.0, 0.0),\n",
    "})\n",
    "plt.rc('axes.spines', **{'bottom':True, 'left':True, 'right':False, 'top':False})\n",
    "\n",
    "### Para formato local\n",
    "import locale\n",
    "### Según Windows o Ubuntu\n",
    "try:\n",
    "    ### Windows\n",
    "    locale.setlocale(locale.LC_ALL, 'esp')\n",
    "except Exception:\n",
    "    ### Ubuntu (action)\n",
    "    locale.setlocale(locale.LC_ALL, 'es_CL.UTF-8')\n",
    "\n",
    "### Otros paquetes\n",
    "import math\n",
    "import requests\n",
    "import os\n",
    "import json as json\n",
    "import datetime\n",
    "import time\n",
    "import IPython.display as display\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "### Solo de uso esporádico\n",
    "import csv\n",
    "from io import StringIO\n",
    "from io import BytesIO\n",
    "import pkg_resources\n",
    "import types\n",
    "\n",
    "### Gracias a joelostblom (https://gitlab.com/joelostblom/session_info)\n",
    "import session_info\n",
    "\n",
    "### Pybtex\n",
    "import pybtex.plugin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtención de datos\n",
    "\n",
    "---\n",
    "\n",
    "### MICITEC\n",
    "\n",
    "En función de que, los datos están ampliamente organizados y trabajados por el <a href=\"https://github.com/MinCiencia/Datos-COVID19\">Ministerio de Ciencia, Tecnología, Conocimiento e Innovación (**MICITEC**) en su GitHub</a> {cite}`MICITEC`, procedemos a leer los archivos .CSV en el siguiente bloque de código. {footcite}`MICITEC`\n",
    "\n",
    "- Los archivos .CSV refieren a \"comma separated values\", que en español significa \"archivos separados por coma\", y si bien, parecieran tener una estructura desorganizada, en verdad tienen un orden por columna y fila, delimitando cada elemento por una coma. En Data Science son ampliamente utilizados, aunque, en secuencias de datos más amplias (y con mayor peso) se suele utilizar el lenguaje de consulta SQL, dado que la librería Pandas, en un archivo .CSV, debe leer uno y cada uno de los datos, por lo que a medida escala el número de datos, el proceso de lectura de un .CSV se torna ineficiente.\n",
    "\n",
    "- Para ejemplo práctico, leer bloque de código ([Ejemplo 1](#ejemplo1)).\n",
    "\n",
    "Sin embargo, al tratar con datos diarios que no han sido registrados por más de dos años, ni con un gran número de variables, no existe ningún inconveniente al trabajar con los archivos separados por coma.\n",
    "\n",
    "### SOCHIMI\n",
    "\n",
    "Los datos de la encuesta nacional de la Sociedad Chilena de Medicina Intensiva (SOCHIMI), del producto 48 (csv48), no los consideramos puesto que estos no serán actualizados a futuro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación (2), haremos un procedimiento similar, pero desde archivos .CSV con mayor número de columnas y brindando como argumento el enlace donde se encuentra el archivo en GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obteniendo datos desde Min. de Ciencia y Tecnología\n",
    "\n",
    "### csv13 (casos acumulativos), producto 13\n",
    "csv13 = pd.read_csv('https://raw.githubusercontent.com/MinCiencia/Datos-COVID19/master/output/producto13/CasosNuevosCumulativo_T.csv')\n",
    "\n",
    "### csv3 (casos por detalle), producto 3\n",
    "csv3_detalle = pd.read_csv('https://raw.githubusercontent.com/MinCiencia/Datos-COVID19/master/output/producto3/TotalesPorRegion.csv')\n",
    "\n",
    "### csv14 (fallecidos cumulativos), producto 14\n",
    "csv14 = pd.read_csv('https://raw.githubusercontent.com/MinCiencia/Datos-COVID19/master/output/producto14/FallecidosCumulativo_T.csv')\n",
    "\n",
    "### csv3 (casos cumulativos), producto 3\n",
    "csv3 = pd.read_csv('https://raw.githubusercontent.com/MinCiencia/Datos-COVID19/master/output/producto3/CasosTotalesCumulativo_T.csv')\n",
    "\n",
    "### csv7 (pcr cumulativos), producto 7\n",
    "csv7 = pd.read_csv('https://raw.githubusercontent.com/MinCiencia/Datos-COVID19/master/output/producto7/PCR_T.csv')\n",
    "\n",
    "### csv36 (residencias sanitarias), producto 36\n",
    "csv36 = pd.read_csv('https://raw.githubusercontent.com/MinCiencia/Datos-COVID19/master/output/producto36/ResidenciasSanitarias.csv')\n",
    "\n",
    "### 2.1. csv48 (sochimi), producto 48\n",
    "#csv48 = pd.read_csv('https://raw.githubusercontent.com/MinCiencia/Datos-COVID19/master/output/producto48/SOCHIMI.csv')\n",
    "\n",
    "### csv54 (r regional), producto 54\n",
    "csv54_regional = pd.read_csv('https://raw.githubusercontent.com/MinCiencia/Datos-COVID19/master/output/producto54/r.regional.csv')\n",
    "\n",
    "### csv54 (r provincial), producto 54\n",
    "csv54_provincial = pd.read_csv('https://raw.githubusercontent.com/MinCiencia/Datos-COVID19/master/output/producto54/r.provincial.csv')\n",
    "\n",
    "### csv8 (camas uci diarias), producto 8\n",
    "csv8 = pd.read_csv('https://raw.githubusercontent.com/MinCiencia/Datos-COVID19/master/output/producto8/UCI_T.csv')\n",
    "\n",
    "### csv58 (camas uci por detalle), producto 58\n",
    "csv58 = pd.read_csv('https://raw.githubusercontent.com/MinCiencia/Datos-COVID19/master/output/producto58/Camas_UCI_diarias.csv')\n",
    "\n",
    "### csv76 (vacunación), producto 76\n",
    "csv76 = pd.read_csv('https://raw.githubusercontent.com/MinCiencia/Datos-COVID19/master/output/producto76/vacunacion.csv')\n",
    "\n",
    "### csv81 (población por edad), producto 81\n",
    "csv81_poblacionedad = pd.read_csv('https://raw.githubusercontent.com/MinCiencia/Datos-COVID19/master/output/producto81/poblacion_comuna_edad.csv')\n",
    "\n",
    "### csv81 (vacunación por edad 1° dosis), producto 81\n",
    "csv81_edad1 = pd.read_csv('https://raw.githubusercontent.com/MinCiencia/Datos-COVID19/master/output/producto81/vacunacion_comuna_edad_1eraDosis.csv')\n",
    "\n",
    "### csv81 (vacunación por edad 2° dosis), producto 81\n",
    "csv81_edad2 = pd.read_csv('https://raw.githubusercontent.com/MinCiencia/Datos-COVID19/master/output/producto81/vacunacion_comuna_edad_2daDosis.csv')\n",
    "\n",
    "### csv81 (vacunación por edad única dosis), producto 81\n",
    "csv81_edadunica = pd.read_csv('https://raw.githubusercontent.com/MinCiencia/Datos-COVID19/master/output/producto81/vacunacion_comuna_edad_UnicaDosis.csv')\n",
    "\n",
    "### csv87 (antígenos por región)\n",
    "csv87 = pd.read_csv('https://raw.githubusercontent.com/MinCiencia/Datos-COVID19/master/output/producto87/Ag.csv')\n",
    "\n",
    "### csv19 (casos activos por comuna), producto 19\n",
    "csv19 = pd.read_csv('https://raw.githubusercontent.com/MinCiencia/Datos-COVID19/master/output/producto19/CasosActivosPorComuna_T.csv')\n",
    "\n",
    "### csv1 (casos confirmados comuna)\n",
    "csv1 = pd.read_csv('https://raw.githubusercontent.com/MinCiencia/Datos-COVID19/master/output/producto1/Covid-19_T.csv')\n",
    "\n",
    "### csv74 (paso a paso histórico)\n",
    "csv74 = pd.read_csv('https://raw.githubusercontent.com/MinCiencia/Datos-COVID19/master/output/producto74/paso_a_paso.csv')\n",
    "\n",
    "### csv82 (movilidad en la semana y el fin de semana)\n",
    "csv82_semana = pd.read_csv('https://raw.githubusercontent.com/MinCiencia/Datos-COVID19/master/output/producto82/ISCI_weeks.csv')\n",
    "csv82_finsemana = pd.read_csv('https://raw.githubusercontent.com/MinCiencia/Datos-COVID19/master/output/producto82/ISCI_weekends.csv')\n",
    "\n",
    "### csv65 (positividad por comuna)\n",
    "csv65 = pd.read_csv('https://raw.githubusercontent.com/MinCiencia/Datos-COVID19/master/output/producto65/PositividadPorComuna.csv')\n",
    "\n",
    "### csv66 (cobertura por comuna)\n",
    "csv66 = pd.read_csv('https://raw.githubusercontent.com/MinCiencia/Datos-COVID19/master/output/producto66/CoberturaPorComuna.csv')\n",
    "\n",
    "### csv67 (oportunidad en la notificación)\n",
    "csv67 = pd.read_csv('https://raw.githubusercontent.com/MinCiencia/Datos-COVID19/master/output/producto67/OportunidadPorComuna.csv')\n",
    "\n",
    "### csv63 (notificación por comuna)\n",
    "csv63 = pd.read_csv('https://raw.githubusercontent.com/MinCiencia/Datos-COVID19/master/output/producto63/NNotificacionPorComuna.csv')\n",
    "\n",
    "### csv64 (BAC por comuna)\n",
    "csv64 = pd.read_csv('https://raw.githubusercontent.com/MinCiencia/Datos-COVID19/master/output/producto64/BACPorComuna.csv')\n",
    "\n",
    "### csv38 (casos fallecidos por comuna, no procesados por DEIS)\n",
    "csv38 = pd.read_csv('https://raw.githubusercontent.com/MinCiencia/Datos-COVID19/master/output/producto38/CasosFallecidosPorComuna.csv')\n",
    "\n",
    "### csv61 (casos fallecidos por comuna, procesados por DEIS)\n",
    "csv61 = pd.read_csv('https://raw.githubusercontent.com/MinCiencia/Datos-COVID19/master/output/producto61/serie_fallecidos_comuna.csv')\n",
    "\n",
    "### csv69 (tasa de incidencia provincial, por cada cien mil habitantes, de casos confirmados, calculada por ICOVID Chile)\n",
    "csv69_provincial = pd.read_csv('https://raw.githubusercontent.com/MinCiencia/Datos-COVID19/master/output/producto69/carga.provincial.ajustada.csv')\n",
    "\n",
    "### csv69 (tasa de incidencia regional, por cada cien mil habitantes, de casos confirmados, calculada por ICOVID Chile)\n",
    "csv69_regional = pd.read_csv('https://raw.githubusercontent.com/MinCiencia/Datos-COVID19/master/output/producto69/carga.regional.ajustada.csv')\n",
    "\n",
    "### csv18 (tasa de incidencia histórica acumulada)\n",
    "csv18 = pd.read_csv('https://raw.githubusercontent.com/MinCiencia/Datos-COVID19/master/output/producto18/TasaDeIncidencia.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis y manipulación de datos\n",
    "\n",
    "---\n",
    "\n",
    "Antes de proceder con el trabajo con los datos, se debe realizar un pequeño análisis, recorriendo aquellas variables que nos sean útiles. Este análisis ya está previamente hecho, dado que, nos basaremos en la disposición de datos del reporte diario del Ministerio de Salud, sumando otros que pueden ser calculados con las librerías de Python a través de operaciones vectoriales sobre las columnas.\n",
    "\n",
    "Sin embargo, tenemos un inconveniente. Públicamente, en los informes diarios del Ministerio de Salud, no se especificaban casos activos y recuperados. Por dicha razón, con fecha anterior al 21 de junio y 29 del mismo mes, del año 2020, no están disponibles las curvas históricas para casos activos y recuperados, respectivamente, en los archivos del GitHub del MICITEC.\n",
    "\n",
    "### Arreglo\n",
    "\n",
    "Para suplir esa falta de datos, los añadiremos de forma manual, los cuales fueron registrados por el Dr. Cristóbal Corral en su seguimiento de la pandemia en Tarapacá. Éstos, fueron estimados de acuerdo a la metodología del Ministerio de Salud en ese entonces.\n",
    "\n",
    "Los datos a añadir, contemplan hasta el 20 de junio del 2020 en los activos, y hasta el 28 de junio del mismo año para los casos recuperados. Posterior a esas fechas, se realizó el cambio de metodología y se empezó a proporcionar las cifras en los reportes diarios. De hecho, los saltos en las gráficas de casos activos y recuperados se explican por los cambios de metodología.\n",
    "\n",
    "### ¿Qué es la manipulación de datos?\n",
    "\n",
    "Por otro lado, suena extraño \"manipular datos\", ¿cierto? La significancia es más simple de lo que parece. Cuando trabajamos con datos, estos suelen venir en formatos no apropiados. En tales casos, una columna que cuantifica debe tener números (int o float) y no palabras (str), del contrario, tendremos inconvenientes a la hora de realizar gráficos. Un ejemplo se puede apreciar a continuación, donde nos interesa la columna de la Región de Tarapacá (y no otras), y también, que las columnas contengan exclusivamente números. Entonces... ¿Por qué alguien pondría una fila de strings (variables de texto) entre medio de columnas con variables numéricas? La función es que podamos identificar a qué región de Chile pertenecen los datos (de otra forma, no podríamos saberlo), pero una vez ya las identificamos, ¡no las necesitamos! Y será necesario limpiar o quitar la fila (en este caso, la fila <b style=\"color:red\">'Región'</b>).\n",
    "\n",
    "| Fecha | Casos nuevos | <b style=\"color:red\">Casos nuevos</b> | <b style=\"color:red\">...</b> |\n",
    "| --- | --- | --- | --- |\n",
    "| <b style=\"color:red\">Región</b> | <b style=\"color:red\">Tarapacá</b> | <b style=\"color:red\">Antofagasta</b> | <b style=\"color:red\">...</b> |\n",
    "| 06-05-2021 | 115 | <b style=\"color:red\">144</b> | <b style=\"color:red\">...</b> |\n",
    "| 05-05-2021 | 101 | <b style=\"color:red\">76</b>  | <b style=\"color:red\">...</b> |\n",
    "| 04-05-2021 | 71 | <b style=\"color:red\">83</b>  | <b style=\"color:red\">...</b> |\n",
    "| ... | ... | <b style=\"color:red\">...</b> | <b style=\"color:red\">...</b> |\n",
    "\n",
    "Todo ésto es parte de lo que se denomina limpieza de datos, que deberemos realizarlo con anterioridad al análisis exploratorio.\n",
    "\n",
    "A continuación, y una vez la data limpia, como también, reconocidas las variables que nos pueden ser útiles, debemos utilizar nuestra creatividad, y generar, a partir de la información que tenemos, nuevas variables que permitan resumir o acotar otras, dando a explicar, de mejor forma, los datos de la pandemia.\n",
    "\n",
    "### Datos por agregar\n",
    "\n",
    "Por tiempo, falta añadir las siguientes variables (*si se requieren, abrir un Issue o solicitarlo directamente*):\n",
    "\n",
    "- Tasa de incidencia histórica por comuna.\n",
    "\n",
    "- Tasa de incidencia histórica por provincia.\n",
    "\n",
    "- Tasa de incidencia histórica en región.\n",
    "\n",
    "- Tasa de incidencia acumulada (*en caso de estar disponible*).\n",
    "\n",
    "### Datos calculados\n",
    "\n",
    "Para efectos de contar con mayor cantidad de variables, se calculan:\n",
    "\n",
    "#### Positividad diaria PCR\n",
    "\n",
    "La positividad PCR entrega el porcentaje de personas positivas de la cantidad de PCR informados en un determinado intervalo de tiempo. En este caso, en el día.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\Large POSITIVIDAD_{diaria} = \\frac{(casos \\ nuevos \\ totales) - (casos \\ por \\ antígeno)}{exámenes \\ pcr \\ informados}\n",
    "\\end{align}\n",
    "$$ (positividad_diaria)\n",
    "\n",
    "#### Positividad media móvil semanal\n",
    "\n",
    "La positividad media móvil semanal se entiende como la media que, a lo menos, requiere siete datos para obtenerse, obteniendo los promedios por ventana de siete días en un determinado conjunto de datos.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\Large POSITIVIDAD_{móvil \\ semanal} = \\frac{1}{7}\\sum_{i=1}^{7} Dato_{i}\n",
    "\\end{align}\n",
    "$$ (positividad_movil)\n",
    "\n",
    "#### Tasa de crecimiento semanal\n",
    "\n",
    "Idea original de Dr. Cristóbal Corral, con una tasa de crecimiento capaz de entregar el cambio diario a partir del cociente entre los casos nuevos del día $n$ y los casos nuevos del día $n-1$. Se modifica y se contempla una tasa de crecimiento semanal, a partir de la media móvil de la sumatoria de los casos nuevos registrados en una semana $n$ y la semana $n-1$.\n",
    "\n",
    "$$ \n",
    "\\begin{align}\n",
    "\\Large TASA_{crecimiento \\ semanal} = \\frac{\\sum_{i=1}^{7} Dato_{i}}{\\sum_{i=7}^{14} Dato_{i}} \n",
    "\\end{align}\n",
    "$$ (tasa_crecimiento)\n",
    "\n",
    "#### Mortalidad específica por cien mil habitantes\n",
    "\n",
    "La mortalidad específica entrega la cantidad de personas que fallecen por una determinada enfermedad, en un determinado período en una población. El determinado período se entiende en razón de que la pandemia aún no finaliza, y sería erróneo considerar la tasa de letalidad sabiendo que, aún no se registra la cantidad de contagiados y fallecidos totales por la enfermedad. En este caso, la contemplaremos por cada 100.000 habitantes.\n",
    "\n",
    "$$ \n",
    "\\begin{align}\n",
    "\\Large MORTALIDAD_{específica} = \\frac{fallecidos \\ acumulados}{población}*100000 \n",
    "\\end{align}\n",
    "$$ (mortalidad_especifica)\n",
    "\n",
    "#### UCI diaria aproximada\n",
    "\n",
    "En razón de que:\n",
    "\n",
    "- No se entrega una ocupación UCI por región en los reportes diarios del Ministerio de Salud.\n",
    "\n",
    "- Los datos disponibles respecto a la cantidad de camas disponibles y utilizadas tienen demora en actualizarse en la base de datos del MICITEC.\n",
    "\n",
    "Ésto nos genera un inconveniente particular, que es no tener un dato diario de la ocupación UCI regional. Para solucionar este problema, ocuparemos una aproximación. A la fecha (2021-05-04), la aproximación UCI diaria tiene un error absoluto del 0.017 ([Ejemplo 2](#ejemplo2)).\n",
    "\n",
    "La aproximación consiste en utilizar los últimos datos disponibles del producto 58 (csv58) y los datos diarios del producto 8 (csv8), calculando la ocupación de la siguiente forma, por media móvil semanal:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\Large UCI_{diaria \\ aproximada} = \\frac{1}{7}\\sum_{i=1}^{7} (\\frac{(pacientes \\ covid_{csv8}) + (pacientes \\ no \\ covid_{csv58})}{(uci \\ disponibles_{csv58})})_{i} \n",
    "\\end{align}\n",
    "$$ (uci_diaria)\n",
    "\n",
    "#### Tasa de casos nuevos por cien mil habitantes\n",
    "\n",
    "Se entiende como la media móvil semanal de casos nuevos por cada cien mil habitantes. Se utiliza ampliamente en el plan Paso a Paso, y debido a la normalización, es un dato perfectamente comparable entre las regiones de Chile. Su cálculo es a partir de:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\Large Tasa_{casos \\ nuevos} = \\frac{100000}{7*población}\\sum_{i=1}^{7} Dato_{i}\n",
    "\\end{align}\n",
    "$$ (tasa_casos)\n",
    "\n",
    "#### Tasa de incidencia (casos diarios)\n",
    "\n",
    "La incidencia (casos nuevos por cien mil habitantes diarios) - *que se puede encontrar en la base de datos* - es estimada con un 95% de confianza por ICOVIDCHILE. \n",
    "\n",
    "El **cálculo de la tasa de incidencia diaria**, a partir de los casos confirmados, es la misma fórmula que de la tasa de casos nuevos por cien mil habitantes, con la diferencia de no aplicar la media móvil semanal y ser cumulativo o acumulativo según lo aclare el nombre de la columna.\n",
    "\n",
    "#### Días por fase del plan Paso a Paso\n",
    "\n",
    "Variable que cuantifica la cantidad de días de una determinada fase del plan del Paso a Paso, por comuna. La variable, en sí, no requiere de una descripción. Se subentiende que, se acumulan los días que una determinada comuna estuvo en una determinada fase, haciendo un \"*reset*\" de días por cambio de fase de la comuna en el Paso a Paso.\n",
    "\n",
    "#### Inmunizaciones\n",
    "\n",
    "Para cálculo de personas personas inmunizadas consideraremos una metodología particular. La razón de la metodología es a razón de ahorrar mayor trabajo en calcular los intervalos de tiempo por inmunización:\n",
    "\n",
    "- Puntualmente, entiéndase por inmunización - *para este cálculo particular* -, **la suma de inmunizaciones eventuales** para aquellas personas con menos de dos semanas de innoculadas con 2° dosis o única (según el laboratorio de la vacuna) **e inmunizaciones completas** para personas con más de dos semanas de innoculadas con 2° dosis o única.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\Large Inmunizadas_{total} = Población - Innoculaciones_{2° \\ dosis} - Innoculaciones_{única \\ dosis}\n",
    "\\end{align}\n",
    "$$ (inmunizadas_total)\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\Large Inmunizadas_{objetivo} = Población*0.8 - Innoculaciones_{2° \\ dosis} - Innoculaciones_{única \\ dosis}\n",
    "\\end{align}\n",
    "$$ (inmunizadas_objetivo)\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\Large Sin_{inmunizar \\ o \\ con \\ protección \\ parcial} = Población - Innoculaciones_{1° \\ dosis}\n",
    "\\end{align}\n",
    "$$ (sin_inmunizar)\n",
    "\n",
    "#### Tasa de activos\n",
    "\n",
    "La tasa de activos, también denominada incidencia (activos), cuantifica la **velocidad de ocurriencia de infectados**. En este caso, se basa en el lapso temporal de los activos, a partir de los infectados en los últimos 11 días.\n",
    "\n",
    "Por otro lado, según *Principales medidas en epidemiología* {cite}``medidas-epidemiologia``, \"*En los estudios epidemiológicos en los que el propósito es la investigación causal o la evaluación de medidas preventivas, el interés está dirigido a la medición del flujo que se establece entre la salud y la enfermedad, es decir, a la aparición de casos nuevos. Como ya se mencionó anteriormente, la medida epidemiológica que mejor expresa este cambio de estado es la incidencia, la cual indica la frecuencia con que ocurren nuevos eventos*\" {footcite}``medidas-epidemiologia``.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\Large Tasa_{activos} = \\frac{Activos_{confirmados} + Activos_{probables}}{población}*100000\n",
    "\\end{align}\n",
    "$$ (incidencia)\n",
    "\n",
    "> La tasa de activos puede variar respecto al informe epidemiológico dado que la del presente repositorio se registra un día después (*con los datos del día anterior por el corte*).\n",
    "\n",
    "\n",
    "### Limpieza de datos\n",
    "\n",
    "En toda recolección de información, se quiera o no, existirá inconsistencia. Algunos días, se genera inconsistencia producto de:\n",
    "\n",
    "- Cambios de criterio.\n",
    "\n",
    "- Suma de cifras de otros días en un día específico (**ajustes históricos considerables**).\n",
    "\n",
    "Ésto afecta las tendencias y las curvas de los datos cumulativos. \n",
    "\n",
    "#### Tratamiento\n",
    "\n",
    "Nuestro trabajo es, dentro de lo posible, limpiar esa inconsistencia. Por lo que, a lo largo del código, se optará por reemplazar los **outliers** (datos atípicos) con cifras del día anterior, **pero, solo en las cifras cumulativas, de modo de no generar descuadre con respecto al Minsal en las cifras acumulativas**.\n",
    "\n",
    "### Manipulando (*ahora sí*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Manipulando datos\n",
    "\n",
    "### Población segregada por comuna\n",
    "poblacion = csv7.loc[1, 'Tarapacá']\n",
    "### Población por comuna\n",
    "poblaciones_comunales = csv38[csv38['Region'] == 'Tarapaca'][:-2]['Poblacion']\n",
    "poblaciones_comunales.index = np.arange(7)\n",
    "\n",
    "### Obteniendo casos cumulativos\n",
    "casos_cumulativos = csv13.loc[:, 'Tarapacá']\n",
    "casos_cumulativos.index = csv13['Region']\n",
    "\n",
    "### Obteniendo casos acumulativos\n",
    "casos_acumulativos = csv3.loc[:, 'Tarapacá']\n",
    "casos_acumulativos.index = csv3['Region']\n",
    "\n",
    "### Obteniendo fallecidos acumulativos\n",
    "fallecidos_acumulativos = csv14.loc[:, 'Tarapacá']\n",
    "fallecidos_diarios = fallecidos_acumulativos - fallecidos_acumulativos.shift(1)\n",
    "fallecidos_acumulativos.index, fallecidos_diarios.index = csv14['Region'], csv14['Region']\n",
    "\n",
    "### Obteniendo PCR\n",
    "pcr_cumulativos = csv7.loc[:, 'Tarapacá'][2:]\n",
    "pcr_cumulativos.index = csv7['Region'][2:]\n",
    "\n",
    "### El día 12 de mayo se registraron más casos de los PCR que se informaron, lo que es imposible\n",
    "### Asignamos los PCR del 13 de mayo de 2020, a los del 12 de mayo del mismo año\n",
    "### Posiblemente, es un dato mal registrado\n",
    "pcr_cumulativos['2020-05-13'] = pcr_cumulativos['2020-05-12']\n",
    "pcr_acumulativos = pcr_cumulativos.cumsum()\n",
    "\n",
    "### Obteniendo UCI diaria con COVID-19\n",
    "uci_diaria = csv8.loc[:, 'Tarapacá'][2:]\n",
    "uci_diaria.index = csv8['Region'][2:]\n",
    "\n",
    "### Obteniendo detalle de casos (sintomáticos, asintomáticos, etc.)\n",
    "casos_detalle = csv3_detalle[csv3_detalle['Region'] == 'Tarapacá']\n",
    "\n",
    "### Obteniendo residencias\n",
    "residencias = csv36[csv36['Region'] == 'Tarapacá']\n",
    "\n",
    "### Obteniendo encuesta nacional de medicina intensiva (desactualizada)\n",
    "# sochimi = csv48[csv48['Region'] == 'Tarapacá']\n",
    "\n",
    "### Obteniendo detalle de UCI semanal\n",
    "uci_detalle = csv58[csv58['Region'] == 'Tarapacá']\n",
    "uci_habilitadas = uci_detalle[uci_detalle['Serie'] == 'Camas UCI habilitadas'].loc[:, '2020-04-14':].transpose().iloc[:, 0]\n",
    "uci_ocupadas_covid = uci_detalle[uci_detalle['Serie'] == 'Camas UCI ocupadas COVID-19'].loc[:, '2020-04-14':].transpose().iloc[:, 0]\n",
    "uci_ocupadas_nocovid = uci_detalle[uci_detalle['Serie'] == 'Camas UCI ocupadas no COVID-19'].loc[:, '2020-04-14':].transpose().iloc[:, 0]\n",
    "\n",
    "### Añadiendo cifras recopiladas por Dr. Cristóbal Corral con metodología de conteo anterior al criterio actual\n",
    "activos_rescatados = [1,4,4,5,5,5,6,8,10,10,12,13,17,20,20,19,22,24,30,33,40,44,52,52,54,60,64,70,72,81,88,99,99,104,109,111,106,120,131,126,130,181,201,217,224,288,324,342,364,383,409,432,484,578,632,700,758,784,797,826,930,982,1038,1077,1152,1186,1264,1302,1389,1369,1452,1466,1519,1540,1549,1598,1658,1734,1727,1745,1705,1696,1720,1747,1696,1736,2066,2019,1987,2000]\n",
    "recuperados_rescatados = [1,4,4,5,5,5,6,8,10,10,12,13,17,20,21,23,26,29,35,38,46,52,62,62,66,73,81,90,93,104,114,128,134,142,155,163,168,182,197,199,211,271,294,321,338,416,458,484,519,546,577,614,681,777,843,971,1052,1105,1135,1242,1388,1466,1557,1623,1729,1800,1945,2079,2232,2340,2504,2571,2654,2782,2937,3064,3215,3357, 3545,3650,3775,3952,4087]\n",
    "\n",
    "### Obteniendo el detalle de los casos\n",
    "casos_con_sintomas = casos_detalle[casos_detalle['Categoria'] == 'Casos nuevos con sintomas'].loc[:, '2020-03-03':].transpose().iloc[:, 0]\n",
    "casos_sin_sintomas = casos_detalle[casos_detalle['Categoria'] == 'Casos nuevos sin sintomas'].loc[:, '2020-03-03':].transpose().iloc[:, 0]\n",
    "casos_sin_notificar = casos_detalle[casos_detalle['Categoria'] == 'Casos nuevos sin notificar'].loc[:, '2020-03-03':].transpose().iloc[:, 0]\n",
    "casos_recuperados = casos_detalle[casos_detalle['Categoria'] == 'Casos confirmados recuperados'].loc[:, '2020-03-03':].transpose().iloc[:, 0]\n",
    "casos_recuperados['2020-04-07':'2020-06-28'] = recuperados_rescatados\n",
    "casos_recuperados_cumulativos = casos_recuperados - casos_recuperados.shift(1)\n",
    "### Limpieza de outlier de 981 (solo en cifras cumulativas para no descuadrar cifra acumulada)\n",
    "casos_recuperados_cumulativos['2020-06-29'] = casos_recuperados_cumulativos['2020-06-28']\n",
    "casos_activos = casos_detalle[casos_detalle['Categoria'] == 'Casos activos confirmados'].loc[:, '2020-03-03':].transpose().iloc[:, 0]\n",
    "casos_activos['2020-03-23':'2020-06-20'] = activos_rescatados\n",
    "casos_activos_probables = casos_detalle[casos_detalle['Categoria'] == 'Casos activos probables'].loc[:, '2020-03-03':].transpose().iloc[:, 0]\n",
    "casos_cumulativos_antigeno = casos_detalle[casos_detalle['Categoria'] == 'Casos nuevos confirmados por antigeno'].loc[:, '2020-03-03':].transpose().iloc[:, 0]\n",
    "casos_acumulativos_reinfeccion = casos_detalle[casos_detalle['Categoria'] == 'Casos con sospecha de reinfeccion'].loc[:, '2020-03-03':].transpose().iloc[:, 0]\n",
    "\n",
    "### Obteniendo el detalle de residencias\n",
    "residencias_cupos = residencias[residencias['Categoria'] == 'cupos totales'].loc[:, '2020-05-29':].transpose().iloc[:, 0]\n",
    "residencias_usuarios = residencias[residencias['Categoria'] == 'usuarios en residencia'].loc[:, '2020-05-29':].transpose().iloc[:, 0]\n",
    "residencias_numero = residencias[residencias['Categoria'] == 'residencias'].loc[:, '2020-05-29':].transpose().iloc[:, 0]\n",
    "\n",
    "### Obteniendo el detalle de SOCHIMI (producto desactualizado e incompleto)\n",
    "#sochimi_uci_ocupadas = sochimi[sochimi['Serie'] == 'Camas ocupadas intensivo'].loc[:, '2020-04-12':].transpose().iloc[:, 0]\n",
    "#sochimi_uci_totales = sochimi[sochimi['Serie'] == 'Camas totales intensivo'].loc[:, '2020-04-12':].transpose().iloc[:, 0]\n",
    "#sochimi_uti_ocupadas = sochimi[sochimi['Serie'] == 'Camas ocupadas intermedio'].loc[:, '2020-04-12':].transpose().iloc[:, 0]\n",
    "#sochimi_uti_totales = sochimi[sochimi['Serie'] == 'Camas totales intermedio'].loc[:, '2020-04-12':].transpose().iloc[:, 0]\n",
    "#sochimi_vmi_covid = sochimi[sochimi['Serie'] == 'Vmi covid19 confirmados'].loc[:, '2020-04-12':].transpose().iloc[:, 0]\n",
    "#sochimi_vmi_sospecha = sochimi[sochimi['Serie'] == 'Vmi covid19 sospechosos'].loc[:, '2020-04-12':].transpose().iloc[:, 0]\n",
    "#sochimi_vmi_ocupados = sochimi[sochimi['Serie'] == 'Vmi ocupados'].loc[:, '2020-04-12':].transpose().iloc[:, 0]\n",
    "#sochimi_vmi_totales = sochimi[sochimi['Serie'] == 'Vmi totales'].loc[:, '2020-04-12':].transpose().iloc[:, 0]\n",
    "\n",
    "### Obteniendo R-efectivo\n",
    "r_regional = csv54_regional[csv54_regional['Region'] == 'Tarapacá'][['fecha','r.estimado']]\n",
    "r_regional.index = r_regional['fecha']\n",
    "r_regional = r_regional['r.estimado']\n",
    "r_provincial = csv54_provincial[csv54_provincial['Region'] == 'Tarapacá'][['fecha','r.estimado', 'Provincia']]\n",
    "r_provincial.index = r_provincial['fecha']\n",
    "r_provincial_iqq = r_provincial[r_provincial['Provincia'] == 'Iquique']['r.estimado']\n",
    "r_provincial_tam = r_provincial[r_provincial['Provincia'] == 'Tamarugal']['r.estimado']\n",
    "\n",
    "### Obteniendo vacunacion\n",
    "vacunacion = csv76[csv76['Region'] == 'Tarapacá'].transpose()\n",
    "vacunacion = vacunacion.drop('Dosis').drop('Region')\n",
    "vacunacion.index, vacunacion = pd.to_datetime(vacunacion.index), vacunacion.astype(int)\n",
    "vacunacion.columns = ['1° Dosis', '2° Dosis', 'Unica dosis']\n",
    "\n",
    "### Obteniendo vacunación por edades (dataframe aparte)\n",
    "x = np.arange(5, 70, 10)\n",
    "vacunacion_etaria = pd.DataFrame([])\n",
    "for i in x:\n",
    "    vacunacion_etaria['{} a {}'.format(csv81_edad1[csv81_edad1['Region'] == 'Tarapaca'].iloc[:, i:i+10].columns[0],\n",
    "                               csv81_edad1[csv81_edad1['Region'] == 'Tarapaca'].iloc[:, i:i+10].columns[-1])] \\\n",
    "    = [csv81_poblacionedad[csv81_poblacionedad['Region'] == 'Tarapaca'].iloc[:, i:i+10].sum().sum(),\n",
    "       csv81_edad1[csv81_edad1['Region'] == 'Tarapaca'].iloc[:, i:i+10].sum().sum(), \n",
    "      csv81_edad2[csv81_edad2['Region'] == 'Tarapaca'].iloc[:, i:i+10].sum().sum(),\n",
    "      csv81_edadunica[csv81_edad2['Region'] == 'Tarapaca'].iloc[:, i:i+10].sum().sum()]\n",
    "vacunacion_etaria.index = ['Poblacion', '1° Dosis', '2° Dosis', 'Unica dosis']\n",
    "vacunacion_etaria = vacunacion_etaria.transpose()\n",
    "\n",
    "### Antígenos en la región\n",
    "antigenos = csv87[csv87['Region'] == 'Tarapacá'].loc[:, '2021-06-05':].transpose()\n",
    "antigenos_acumulativos = antigenos.cumsum()\n",
    "\n",
    "### Obteniendo datos comunales\n",
    "casoscomuna_acumulativos = csv1[csv1.columns[csv1.columns.str.contains('^Tarapac', na=False)]][4:]\n",
    "casoscomuna_acumulativos.columns = 'Casos acumulados en ' + csv1[csv1.columns[csv1.columns.str.contains('^Tarapac', na=False)]].iloc[1].astype(str).\\\n",
    "replace('Camina', 'Camiña').replace('Desconocido Tarapaca', 'Comuna desconocida')\n",
    "casoscomuna_acumulativos.index = csv1['Region'][4:]\n",
    "casoscomuna_acumulativos = casoscomuna_acumulativos.drop('Tasa')\n",
    "\n",
    "casoscomuna_activos = csv19[csv19.columns[csv19.columns.str.contains('^Tarapac', na=False)]][4:]\n",
    "casoscomuna_activos.columns = 'Casos activos en ' + csv19[csv19.columns[csv19.columns.str.contains('^Tarapac', na=False)]].iloc[1].astype(str).\\\n",
    "replace('Camina', 'Camiña').replace('Desconocido Tarapaca', 'Comuna desconocida')\n",
    "casoscomuna_activos.index = csv19['Region'][4:]\n",
    "casoscomuna_activos = casoscomuna_activos[casoscomuna_activos.columns[:-1]]\n",
    "incidencia_activos = (((casos_activos + casos_activos_probables)/poblacion)*100000)\n",
    "\n",
    "### Paso a paso histórico por comuna (descartamos zonas rurales)\n",
    "pasopaso_comuna = csv74[csv74['region_residencia'] == 'Tarapacá'].transpose().loc[:, csv74[csv74['region_residencia'] == 'Tarapacá'].transpose().loc['zona',:] != 'Rural']\n",
    "pasopaso_comuna.columns = 'Paso a Paso ' + pasopaso_comuna.transpose().loc[:, 'comuna_residencia']\n",
    "pasopaso_comuna = pasopaso_comuna.drop(['codigo_region', 'codigo_comuna', 'comuna_residencia', 'zona', 'region_residencia'])\n",
    "\n",
    "### Movilidad\n",
    "movilidad_sem = csv82_semana[csv82_semana['region'] == 1]\n",
    "movilidad_finsem = csv82_finsemana[csv82_finsemana['region'] == 1]\n",
    "movilidad_comuna = pd.concat([movilidad_sem, movilidad_finsem])\n",
    "movilidad_comuna['fecha_inicio'], movilidad_comuna['fecha_termino'] = pd.to_datetime(movilidad_comuna['fecha_inicio']), pd.to_datetime(movilidad_comuna['fecha_termino'])\n",
    "movilidad_comuna = movilidad_comuna.sort_values(by=['fecha_inicio'])\n",
    "\n",
    "### Gracias a Erfan (stackoverflow.com/a/57334167/13746427) ###\n",
    "movilidad_comuna['Fecha'] = movilidad_comuna.apply(\n",
    "    lambda x: pd.date_range(x['fecha_inicio'], x['fecha_termino']), axis=1\n",
    ")\n",
    "movilidad_comuna = (\n",
    "    movilidad_comuna.explode('Fecha', ignore_index=True)\n",
    "    .drop(columns=['fecha_inicio', 'fecha_termino'])\n",
    ")\n",
    "\n",
    "movilidad_comuna.index = (movilidad_comuna['Fecha'])\n",
    "### ¿Por qué no ocupar el Paso a Paso histórico de este archivo? Por la frecuencia de actualización ###\n",
    "movilidad_comuna = movilidad_comuna.drop(['region', 'semana','paso', 'region', 'comuna', 'var_salidas_cota_inferior', \\\n",
    "                                         'var_salidas_cota_superior', 'Fecha'], axis=1)\n",
    "### Finalmente, código que nos segrega por comuna los valores de la movilidad ###\n",
    "movilidad = pd.DataFrame([])\n",
    "for comuna in pd.unique(movilidad_comuna.transpose().loc['nom_comuna', :]):\n",
    "    exec('movilidad[\"{}\"] = movilidad_comuna[movilidad_comuna[\"nom_comuna\"] == \"{}\"][\"var_salidas\"]'\\\n",
    "         .format(str('Movilidad ' + comuna.capitalize()), comuna))\n",
    "movilidad.index = movilidad.index.astype(str)\n",
    "movilidad = movilidad.loc['2020-03-03':, :]\n",
    "\n",
    "### Arreglamos tilde para coincidir\n",
    "csv61['Region'] = csv61['Region'].replace('Tarapacá', 'Tarapaca')\n",
    "\n",
    "### Notificación PCR, búsqueda activa, positividad, cobertura de testeo, oportunidad en la notificación por comuna,\n",
    "### fallecidos no procesados por deis y fallecidos procesados por deis\n",
    "### Se rellenan días sin registro con la última observación válida\n",
    "### Exceptuando días antes del primer caso y últimos días sin información ###\n",
    "csvs = ['csv63', 'csv64', 'csv65', 'csv66', 'csv67', 'csv38', \"csv61[csv61['CIE 10'] == 'U07.1']\", \"csv61[csv61['CIE 10'] == 'U07.2']\"]\n",
    "var = ['notificacion', 'bac', 'positividad', 'cobertura', 'oportunidad', 'fallecidos', 'fallecidosdeis_conf', 'fallecidosdeis_prob']\n",
    "nom = ['Notificacion PCR', 'BAC' , 'Positividad', 'Cobertura de testeo', 'Oportunidad en notificacion', 'Fallecidos', \\\n",
    "      'Fallecidos confirmados DEIS', 'Fallecidos probables DEIS']\n",
    "i = 0\n",
    "for csv in csvs:\n",
    "    exec('{}_comuna = pd.DataFrame([], index=casos_cumulativos.index)'.format(var[i]))\n",
    "    exec('{}_comuna = {}_comuna.join({}[{}[\"Region\"] == \"Tarapaca\"].transpose())'.format(var[i], var[i], csv, csv))\n",
    "    exec('{}_comuna.columns = \"{} \" + {}[{}[\"Region\"] == \"Tarapaca\"].transpose().loc[\"Comuna\", :].replace(\"Camina\", \"Camiña\")'.format(var[i], nom[i], csv, csv))\n",
    "    exec('for col in {}_comuna: \\\n",
    "        {}_comuna[col]\\\n",
    "        [{}_comuna[col].first_valid_index():{}_comuna[col].last_valid_index()] = \\\n",
    "        {}_comuna[col]\\\n",
    "        [{}_comuna[col].first_valid_index():{}_comuna[col].last_valid_index()]\\\n",
    "        .fillna(method=\"ffill\", inplace=False)'.format(var[i], var[i], var[i], var[i], var[i], var[i], var[i]))\n",
    "    i += 1\n",
    "\n",
    "### Incidencia acumulada por comuna\n",
    "incidencia_acumulada = csv18[csv18.Region == 'Tarapaca'].transpose().drop(['Region', 'Codigo region', 'Comuna',\n",
    "                                                                       'Codigo comuna', 'Poblacion'])\n",
    "incidencia_acumulada.columns = 'Incidencia acumulada ' + csv18[\n",
    "    csv18.Region == 'Tarapaca'].transpose().loc['Comuna', :].replace('Total', 'regional')\n",
    "    \n",
    "### Otras cifras\n",
    "uciocupacion_nacional = round(((int(csv58[(csv58['Region'] == 'Total') & (csv58['Serie'] == 'Camas UCI ocupadas no COVID-19')].\\\n",
    "                         transpose().iloc[-1]) + int(csv58[(csv58['Region'] == 'Total') & (csv58['Serie'] == 'Camas UCI ocupadas COVID-19')]\\\n",
    "                         .transpose().iloc[-1]))/csv58[(csv58['Region'] == 'Total') & (csv58['Serie'] == 'Camas UCI habilitadas')]\\\n",
    "                         .transpose().iloc[-1])[16] * 100, 0)\n",
    "\n",
    "### Tasa de incidencia (tasa de casos nuevos pero sin media móvil sem., i. e. casos nuevos por cien mil hab.)\n",
    "### Regional\n",
    "incidencia_regional = csv69_regional[csv69_regional.Region == 'Tarapacá'].drop(\n",
    "    ['Codigo region', 'carga.liminf', 'carga.lisup', 'Region'], axis=1)\n",
    "incidencia_regional.index = incidencia_regional.fecha\n",
    "incidencia_regional.drop(['fecha'], axis=1, inplace=True)\n",
    "### Provincial\n",
    "incidencia_provincial = csv69_provincial[csv69_provincial['Region'] == 'Tarapacá'][['fecha','carga.estimada', 'Provincia']]\n",
    "incidencia_provincial.index = incidencia_provincial['fecha']\n",
    "incidencia_provincial_iqq = incidencia_provincial[incidencia_provincial['Provincia'] == 'Iquique']['carga.estimada']\n",
    "incidencia_provincial_tam = incidencia_provincial[incidencia_provincial['Provincia'] == 'Tamarugal']['carga.estimada']\n",
    "\n",
    "### Tasa de casos nuevos por provincia\n",
    "tasacasosnuevos_provincial_iqq = incidencia_provincial_iqq.rolling(window=7).mean()\n",
    "tasacasosnuevos_provincial_tam = incidencia_provincial_tam.rolling(window=7).mean()\n",
    "\n",
    "### Datos calculados ###\n",
    "\n",
    "### Positividad PCR sin redondear\n",
    "positividad_diaria = ((casos_cumulativos - casos_cumulativos_antigeno)/pcr_cumulativos)*100\n",
    "### Rellenamos datos anteriores al primer registro de los antígenos\n",
    "positividad_diaria = positividad_diaria.fillna(100*(casos_cumulativos)/pcr_cumulativos)\n",
    "\n",
    "### Positividad media móvil redondeada\n",
    "positividad_media_movil = positividad_diaria.rolling(7).mean().round(0)\n",
    "### Rellenamos datos anteriores al primer registro de los antígenos\n",
    "positividad_media_movil = positividad_diaria.fillna(100*(casos_cumulativos)/pcr_cumulativos).rolling(7).mean().round(0)\n",
    "\n",
    "## Positividad PCR redondeada\n",
    "positividad_diaria = positividad_diaria.round(0)\n",
    "\n",
    "### Positividad diaria ANTÍGENO\n",
    "positividad_antigeno = (casos_cumulativos_antigeno[antigenos.first_valid_index():].transpose()/\n",
    "      antigenos[antigenos.first_valid_index():].transpose() * 100).transpose()\n",
    "\n",
    "### Positividad media móvil ANTÍGENO\n",
    "positividad_antigeno_media_movil = (casos_cumulativos_antigeno[antigenos.first_valid_index():].transpose()/\n",
    "      antigenos[antigenos.first_valid_index():].transpose() * 100).transpose().rolling(7).mean()\n",
    "\n",
    "### Tasa de crecimiento semanal y diaria\n",
    "crecimiento = casos_cumulativos.rolling(7).sum()/casos_cumulativos.rolling(7).sum().shift(7)\n",
    "crecimientodiario = casos_cumulativos/casos_cumulativos.shift(1)\n",
    "### Limpieza de outlier de 41\n",
    "crecimientodiario['2020-12-13'] = crecimientodiario['2020-12-12']\n",
    "\n",
    "### Mortalidad específica por cien mil habitantes\n",
    "mortalidad_especifica = (((fallecidos_acumulativos) / poblacion)*100000)\n",
    "\n",
    "### Mortalidad específica por cien mil habitantes por comuna\n",
    "j = 0\n",
    "me_comuna = pd.DataFrame([])\n",
    "for col in fallecidosdeis_conf_comuna:\n",
    "    me_comuna['Mortalidad especifica comunal {} *'.format(col[28:])] = fallecidosdeis_conf_comuna[col]/poblaciones_comunales[j]*100000\n",
    "    me_comuna['Mortalidad especifica comunal {} *'.format(col[28:])] = me_comuna['Mortalidad especifica comunal {} *'.format(col[28:])].astype(float)\n",
    "    j += 1\n",
    "    \n",
    "### UCI diaria aproximada, real y error absoluto\n",
    "uci_aprox = (100*(uci_diaria + uci_ocupadas_nocovid)/uci_habilitadas).rolling(7).mean()\n",
    "### Rellenamos con últimos disponibles datos las filas faltantes\n",
    "uci_aprox.loc[uci_aprox.last_valid_index():] = (100*(uci_diaria + uci_ocupadas_nocovid[uci_ocupadas_nocovid.last_valid_index()])/uci_habilitadas[uci_habilitadas.last_valid_index()]).rolling(7).mean()\n",
    "uci_real = (100*(uci_ocupadas_covid + uci_ocupadas_nocovid)/uci_habilitadas).rolling(7).mean()\n",
    "error_abs = abs(((uci_real) - (uci_aprox[:uci_habilitadas.last_valid_index()])))\n",
    "\n",
    "### Tasa de casos nuevos por cien mil habitantes\n",
    "tasa_casosnuevos = ((casos_cumulativos.rolling(window=7).mean()/poblacion)*100000)\n",
    "\n",
    "### Días por fase del plan Paso a Paso\n",
    "### Gracias a P.Tillmann (stackoverflow.com/q/25119524/13746427), código para contar duración en días por fase ###\n",
    "for col in pasopaso_comuna:\n",
    "    pasopaso_comuna['Paso a Paso (dias) ' + col[5:]] = pasopaso_comuna.groupby((pasopaso_comuna[col] != pasopaso_comuna[col].shift(1)).cumsum()).cumcount()\n",
    "\n",
    "### Población yomevacuno\n",
    "poblacion_yomevacuno = 286597"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uniendo en una sola tabla\n",
    "\n",
    "---\n",
    "\n",
    "En razón de contar con los datos de la Región de Tarapacá unificados, procederemos a unir todos los datos en una tabla (DataFrame). Absolutamente todos las salidas (imágenes, archivos, descripciones, etc.) se basan en ella.\n",
    "\n",
    "### ¿Por qué unificar los datos?\n",
    "\n",
    "La primera vez que trabajé con código en Ciencia de Datos, recuerdo haber utilizado las bases de datos de pétalos y sépalos en R Studio, y me preguntaba, ¿podré algún día generar algo similar en base a determinadas observaciones? Quizás, por allí va el por qué del querer unificar todos los datos en un solo archivo, aunque también, en el anhelo que le pueda servir a alguien en un futuro no muy lejano para cuantificar las cifras de la pandemia del COVID-19 en la Región de Tarapacá... Por cierto, nací iquiqueño y al día en que escribo, 31/05/2021, estoy en vías de emprender migración a otra ciudad. Quizás, Numeral.lab, es el aporte a esta tierra que me brindó, junto con mi familia, todo lo que soy (para bien o para mal, todo es dual). \n",
    "\n",
    "Los cambios siempre son para mejor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uniendo datos\n",
    "\n",
    "### Tabla de todos los datos\n",
    "dfs = [casos_acumulativos, casos_recuperados, fallecidos_acumulativos,\n",
    "       casos_activos, casos_activos_probables, casos_cumulativos, casos_con_sintomas,\n",
    "       casos_sin_sintomas, casos_sin_notificar, casos_cumulativos_antigeno,\n",
    "       casos_acumulativos_reinfeccion, casos_recuperados_cumulativos, fallecidos_diarios, antigenos, antigenos_acumulativos,\n",
    "       pcr_cumulativos, pcr_acumulativos, residencias_cupos, residencias_usuarios,\n",
    "       residencias_numero, uci_habilitadas, uci_diaria, uci_ocupadas_nocovid, uci_real, r_regional,\n",
    "       r_provincial_iqq, r_provincial_tam, positividad_diaria, vacunacion, casoscomuna_acumulativos, \n",
    "       casoscomuna_activos, pasopaso_comuna, movilidad, notificacion_comuna, bac_comuna, positividad_comuna,\n",
    "       cobertura_comuna, oportunidad_comuna, fallecidos_comuna, fallecidosdeis_conf_comuna, fallecidosdeis_prob_comuna,\n",
    "       incidencia_regional, incidencia_provincial_iqq, incidencia_provincial_tam, tasacasosnuevos_provincial_iqq,\n",
    "       tasacasosnuevos_provincial_tam, incidencia_acumulada,\n",
    "       positividad_media_movil, mortalidad_especifica,\n",
    "       crecimiento, crecimientodiario, uci_aprox, error_abs, tasa_casosnuevos, positividad_antigeno,\n",
    "       positividad_antigeno_media_movil, me_comuna, incidencia_activos]\n",
    "\n",
    "### Unimos a la tabla anterior y rellenamos valores NaN (Not a Number o no definido)\n",
    "df = pd.concat(dfs, join='outer', axis=1)\n",
    "\n",
    "### Asignamos nombres de columnas y formateamos datos\n",
    "df.columns = ['Casos confirmados acumulados', 'Casos recuperados acumulados', 'Casos fallecidos acumulados',\n",
    "              'Casos activos confirmados', 'Casos activos probables', 'Casos nuevos', 'Casos nuevos con sintomas',\n",
    "              'Casos nuevos sin sintomas', 'Casos nuevos por laboratorio', 'Casos nuevos por antigeno',\n",
    "              'Casos con sospecha de reinfeccion', 'Casos recuperados nuevos', 'Casos fallecidos nuevos',\n",
    "              'Antigenos informados nuevos', 'Antigenos informados acumulados','PCR informados nuevos', \n",
    "              'PCR informados acumulados', 'Cupos en residencias',\\\n",
    "              'Usuarios en residencias', 'Numero de residencias', 'UCI habilitadas', 'UCI ocupadas por confirmados',\n",
    "              'UCI ocupadas por no confirmados', 'UCI ocupacion media movil real', 'Re regional', 'Re Iquique',\n",
    "              'Re Tamarugal', 'Positividad diaria', 'Vacunados acumulados 1° dosis', 'Vacunados acumulados 2° dosis',\n",
    "              'Vacunados acumulados unica dosis', 'Casos acumulados en Alto Hospicio', 'Casos acumulados en Camiña',\n",
    "              'Casos acumulados en Colchane',\n",
    "              'Casos acumulados en Huara', 'Casos acumulados en Iquique', 'Casos acumulados en Pica',\n",
    "              'Casos acumulados en Pozo Almonte', 'Casos acumulados en Comuna desconocida', \n",
    "              'Casos activos en Alto Hospicio', 'Casos activos en Camiña', 'Casos activos en Colchane',\n",
    "              'Casos activos en Huara', 'Casos activos en Iquique', 'Casos activos en Pica', \n",
    "              'Casos activos en Pozo Almonte', 'Casos activos en Comuna desconocida' ,'Paso a Paso Alto Hospicio',\n",
    "              'Paso a Paso Camiña', 'Paso a Paso Colchane', 'Paso a Paso Huara', 'Paso a Paso Iquique',\n",
    "              'Paso a Paso Pica', 'Paso a Paso Pozo Almonte', 'Paso a Paso (dias) Alto Hospicio',\n",
    "              'Paso a Paso (dias) Camiña', 'Paso a Paso (dias) Colchane', 'Paso a Paso (dias) Huara',\n",
    "              'Paso a Paso (dias) Iquique', 'Paso a Paso (dias) Pica', 'Paso a Paso (dias) Pozo Almonte', \n",
    "              'Movilidad Iquique', 'Movilidad Pica', 'Movilidad Alto Hospicio',\n",
    "              'Movilidad Pozo almonte', 'Movilidad Huara', 'Notificacion PCR Alto Hospicio',\n",
    "              'Notificacion PCR Camiña', 'Notificacion PCR Colchane', 'Notificacion PCR Huara',\n",
    "              'Notificacion PCR Iquique', 'Notificacion PCR Pica', 'Notificacion PCR Pozo Almonte',\n",
    "              'BAC Alto Hospicio', 'BAC Camiña', 'BAC Colchane', 'BAC Huara', 'BAC Iquique', 'BAC Pica',\n",
    "              'BAC Pozo Almonte', 'Positividad Alto Hospicio', 'Positividad Camiña', 'Positividad Colchane',\n",
    "              'Positividad Huara', 'Positividad Iquique', 'Positividad Pica', 'Positividad Pozo Almonte',\n",
    "              'Cobertura de testeo Alto Hospicio', 'Cobertura de testeo Camiña', 'Cobertura de testeo Colchane',\n",
    "              'Cobertura de testeo Huara', 'Cobertura de testeo Iquique', 'Cobertura de testeo Pica',\n",
    "              'Cobertura de testeo Pozo Almonte', 'Oportunidad en notificacion Alto Hospicio',\n",
    "              'Oportunidad en notificacion Camiña', 'Oportunidad en notificacion Colchane',\n",
    "              'Oportunidad en notificacion Huara', 'Oportunidad en notificacion Iquique',\n",
    "              'Oportunidad en notificacion Pica', 'Oportunidad en notificacion Pozo Almonte', 'Fallecidos Alto Hospicio',\n",
    "              'Fallecidos Camiña', 'Fallecidos Colchane', 'Fallecidos Huara', 'Fallecidos Iquique', 'Fallecidos Pica',\n",
    "              'Fallecidos Pozo Almonte', 'Fallecidos Comuna desconocida', 'Fallecidos total comunal',\n",
    "              'Fallecidos confirmados DEIS Alto Hospicio','Fallecidos confirmados DEIS Camiña',\n",
    "              'Fallecidos confirmados DEIS Colchane','Fallecidos confirmados DEIS Huara',\n",
    "              'Fallecidos confirmados DEIS Iquique','Fallecidos confirmados DEIS Pica',\n",
    "              'Fallecidos confirmados DEIS Pozo Almonte', 'Fallecidos probables DEIS Alto Hospicio',\n",
    "              'Fallecidos probables DEIS Camiña','Fallecidos probables DEIS Colchane', 'Fallecidos probables DEIS Huara',\n",
    "              'Fallecidos probables DEIS Iquique', 'Fallecidos probables DEIS Pica',\\\n",
    "              'Fallecidos probables DEIS Pozo Almonte', \n",
    "              'Incidencia regional estimada', 'Incidencia Iquique estimada', 'Incidencia Tamarugal estimada',\n",
    "              'Tasa de casos nuevos Iquique estimada', 'Tasa de casos nuevos Tamarugal estimada', \n",
    "              'Incidencia acumulada Alto Hospicio', 'Incidencia acumulada Camina',\n",
    "              'Incidencia acumulada Colchane', 'Incidencia acumulada Huara',\n",
    "              'Incidencia acumulada Iquique', 'Incidencia acumulada Pica',\n",
    "              'Incidencia acumulada Pozo Almonte', 'Incidencia acumulada regional',\n",
    "              'Positividad media movil *', 'Mortalidad especifica *', 'Crecimiento semanal *', 'Crecimiento diario *',\n",
    "              'UCI ocupacion media movil aprox *', 'UCI error abs *','Tasa casos nuevos *', 'Positividad antigeno *',\n",
    "              'Positividad antigeno media movil *', 'Mortalidad especifica comunal Alto Hospicio *', 'Mortalidad especifica comunal Camiña *',\n",
    "              'Mortalidad especifica comunal Colchane *', 'Mortalidad especifica comunal Huara *',\n",
    "              'Mortalidad especifica comunal Iquique *', 'Mortalidad especifica comunal Pica *',\n",
    "              'Mortalidad especifica comunal Pozo Almonte *', 'Tasa de activos (incidencia) *']\n",
    "\n",
    "### Redondeamos a solo dos cifras significativas\n",
    "df = df.round(2)\n",
    "\n",
    "### Pasamos el index (índice) a objeto datetime (fecha) y le asignamos nombre\n",
    "df.index = pd.to_datetime(df.index)\n",
    "df.index = df.index.rename('Fecha')\n",
    "\n",
    "### Imprimimos el DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exportando información\n",
    "\n",
    "---\n",
    "\n",
    "Deberemos exportar la información que trabajamos, y para ello, utilizaremos:\n",
    "\n",
    "- Archivos .CSV (sí, generaremos una serie de archivos).\n",
    "\n",
    "- Infografías (archivos de imagen).\n",
    "\n",
    "- Descripciones regionales.\n",
    "\n",
    "- Gráficos (para entender una tendencia en segundos).\n",
    "\n",
    "- Entre otros.\n",
    "\n",
    "### Infografías generadas\n",
    "\n",
    "Por lo general, todas las infografías las considero una \"burbuja regional\". Mi forma de verlas, desde un principio, fue desarrollar a nivel de la Región de Tarapacá, y luego, en otras regiones. Definitivamente, la contribución hubiese sido enorme si lo hubiese desarrollado a nivel interregional. Sin embargo, la primera versión del código era incapaz de actualizarse (había mucha dependencia en las líneas de código, y hasta incluso, código repetido), por lo que la modificación de una sola línea estropeaba todo el script.\n",
    "\n",
    "En contraste del párrafo anterior, el presente código es menos dependiente y más eficiente. Por lo que, es posible modificarlo a nivel interregional. El problema es que no cuento con el tiempo de hacerlo, y tampoco creo sea necesario a este nivel de la pandemia. Existen otras muchas contribuciones, como la de Juan Cristóbal Olivares: Para visitarla, busca <a href=\"https://www.instagram.com/covid19statscl/\">covid19statscl</a> en Instagram, que es una plataforma que visualiza la pandemia por regiones, desarrollada por él.\n",
    "\n",
    "#### ¿Cómo realizabas las infografías antes de automatizar el proceso?\n",
    "\n",
    "Básicamente, tenía una plantilla hecha en Photoshop, y tenía que modificar todos los días las líneas de texto, copiando y pegando texto, y el mismo proceso era para las imágenes de los gráficos. ¡Me tomaba 30 min.! Era un proceso tedioso y altamente susceptible a equivocaciones. Por dicha razón, realicé el siguiente script, no solo organizando el código y haciéndolo más amigable (dentro de mis posibilidades), sino también, utilizando IPython para modificar las plantillas y de esa forma, reducir considerablemente el proceso de elaboración de los informes (o infografías, como lo desees ver). Es más, desde los 30 min., el proceso actual demora aprox. 20 a 30s. en rellenar los campos, y otros 10 a 15s. en hacer el proceso manual de subir el reporte a Instagram.\n",
    "\n",
    "#### ¿Por qué no automatizaste el proceso de subida a Instagram?\n",
    "\n",
    "Por miedo y en parte, desconocimiento. Instagram no es amigo de los bots, por lo que opté por evitar automatizar la subida a Instagram (y de esa forma, evitar ser baneado).\n",
    "\n",
    "#### ¿Cuántas infografías generaste?\n",
    "\n",
    "Las expongo a continuación:\n",
    "\n",
    "- <b>Reporte diario</b>\n",
    "\n",
    "El más numeroso en la cuenta de Instagram. Es el reporte diario del COVID-19, con el que comenzó Numeral.lab; está basado en el reporte diario del Ministerio de Salud, ahondando con mayor profundidad en los indicadores epidemiológicos.\n",
    "\n",
    "- <b>Indicador de fase</b>\n",
    "\n",
    "El plan Paso a Paso y la capacidad de poder \"predecirlo\". El indicador de fase surgió como una idea de saber, qué tan cerca o qué tan distantes se estaba de los avances o retrocesos de fase, en términos de confinamiento o desconfinamiento. La idea original la desarrollé un día por la noche, e hizo boom en redes sociales. El miembro del comité científico COVID-19 de la Universidad Arturo Prat, el Dr. Cristóbal Corral, fue capaz de explicarlo brevemente a los medios: Un termómetro del Paso a Paso.\n",
    "\n",
    "La primera versión de este reporte fue subida por última vez el 12/05/2021, que fue la 36° edición {cite}`NUMERALAB-INDICADORFASE`. Consistía en una aproximación provincial, es decir, una generalización en torno a las comunas de Iquique o del Tamarugal. ¿Cómo se realizaba el cálculo? Pues, no había cálculo (más que obtener o trabajar los datos disponibles), sino que, se basaba en condicionales (o restricciones): Si se cumplen todos los indicadores, se puede estar en tal fase del plan Paso a Paso por provincia. Evidentemente, no era del todo certero, particularmente, porque no consideraba variables temporales. {footcite}`NUMERALAB-INDICADORFASE`\n",
    "\n",
    "La segunda versión de este reporte fue subida, inicialmente, el 02/05/2021, que fue la 37° edición. Fue procesada en el siguiente script (This is the way 2), y se basa en un problema de clasificación. Para mayor información del cómo funciona y  sus fundamentos, recomiendo ver el siguiente notebook.\n",
    "\n",
    "- <b>Reporte comunal</b>\n",
    "\n",
    "El reporte comunal es, posiblemente, el reporte más simple de todos: Es un reporte que entrega la situación comunal en torno a los cambios del plan Paso a Paso, como también, los casos activos de COVID-19 por comuna, de acuerdo al informe epidemiológico.\n",
    "\n",
    "- <b>Balance de vacunas</b>\n",
    "\n",
    "En período de práctica, me vi en la necesidad de hacer nuevas cosas. En diciembre de 2020 y enero de 2021 era alta la expectativa respecto a la campaña de vacunación \"Yo me vacuno\" impulsada por el Ministerio de Salud. Ello coincidió con que Juan Cristóbal Olivares, ingeniero de Amazon, contribuyó en el repositorio del MICITEC con un \"dataproduct\" (datos) de vacunación a nivel nacional. Entonces, haciendo uso de su contribución, desarrollé el \"Avance de vacunas\", luego denominado \"Balance vacunas\". \n",
    "\n",
    "En un principio, brindaba la comparativa regional en torno al proceso de vacunación de forma estandarizada. Sin embargo, luego lo modifiqué para que, tal como el reporte diario, difundiese información sobre el proceso de vacunación a nivel regional.\n",
    "\n",
    "- <b>Toque de queda 00:00 hrs.</b>\n",
    "\n",
    "Se añade reporte que hace seguimiento a los indicadores para el toque de queda a las 00:00 hrs. en la Región de Tarapacá, dado que llegaron muchas dudas con respecto a."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportando información\n",
    "\n",
    "### df a csv (numeral.csv) ###\n",
    "df.to_csv('../../out/site/csv/numeralab.csv', index=True)\n",
    "\n",
    "### Índices\n",
    "weekstart_data = df['Casos nuevos'].last_valid_index() - datetime.timedelta(6)\n",
    "weekend_data = df['Casos nuevos'].last_valid_index()\n",
    "weekend_datay = weekend_data - datetime.timedelta(1)\n",
    "weekstart2_data = df['Casos nuevos'].last_valid_index() - datetime.timedelta(13)\n",
    "\n",
    "### Cifras región\n",
    "\n",
    "### Balance histórico de casos ###\n",
    "pd.DataFrame([df['Casos nuevos'],\n",
    "              df['Casos recuperados nuevos'],\n",
    "              df['Casos fallecidos nuevos']\n",
    "              ], index=['Casos nuevos históricos', 'Recuperados nuevos históricos', \n",
    "                        'Fallecidos nuevos históricos']\n",
    "              ).transpose().to_csv('../../out/site/csv/data1.csv')\n",
    "\n",
    "### Balance histórico de activos ###\n",
    "pd.DataFrame([df['Casos activos confirmados'][df['Casos activos probables'].first_valid_index():],\n",
    "              df['Casos activos probables'][df['Casos activos probables'].first_valid_index():]]\n",
    "              ).transpose().to_csv('../../out/site/csv/data2.csv')\n",
    "\n",
    "### Balance histórico de casos acumulados ###\n",
    "pd.DataFrame([df['Casos confirmados acumulados'],\n",
    "              df['Casos recuperados acumulados'],\n",
    "              df['Casos activos confirmados'],\n",
    "              df['Casos fallecidos acumulados']]\n",
    "              ).transpose().to_csv('../../out/site/csv/data3.csv')\n",
    "\n",
    "### Tendencia región\n",
    "\n",
    "### Casos ###\n",
    "pd.DataFrame([df['Casos nuevos'].rolling(7).mean(),\n",
    "              df['Casos recuperados nuevos'].rolling(7).mean(),\n",
    "              df['Casos fallecidos nuevos'].rolling(7).mean()\n",
    "              ], index=['Media móvil semanal de casos nuevos', 'Media móvil semanal de recuperados nuevos', \n",
    "                        'Media móvil semanal de fallecidos nuevos']\n",
    "              ).transpose().round(2).to_csv('../../out/site/csv/data4.csv')\n",
    "\n",
    "### Positividad ###\n",
    "pd.DataFrame([df['Positividad diaria'],\n",
    "              df['Positividad media movil *']]\n",
    "              ).transpose().to_csv('../../out/site/csv/data5.csv')\n",
    "\n",
    "### Número de reproducción efectivo ###\n",
    "pd.DataFrame([df['Re regional'],\n",
    "              df['Re Iquique'],\n",
    "              df['Re Tamarugal']]\n",
    "              ).transpose().to_csv('../../out/site/csv/data6.csv')\n",
    "\n",
    "### Incidencia acumulada por provincia ###\n",
    "pd.DataFrame(df.loc[:, df.columns.str.contains('Incidencia') \n",
    "      & df.columns.str.contains('acumulada')]).to_csv('../../out/site/csv/data7.csv')\n",
    "\n",
    "### Incidencia por provincia diaria ###\n",
    "pd.DataFrame(df.loc[:, df.columns.str.contains('Incidencia') \n",
    "      & ~df.columns.str.contains('acumulada')]).to_csv('../../out/site/csv/data8.csv')\n",
    "\n",
    "### Tasa de casos nuevos por provincia ###\n",
    "pd.DataFrame(df.loc[:, df.columns.str.contains('Tasa de casos nuevos') \n",
    "      & ~df.columns.str.contains('acumulada')]).to_csv('../../out/site/csv/data9.csv')\n",
    "\n",
    "\n",
    "\n",
    "### Tasa de crecimiento diaria y media móvil semanal ###\n",
    "pd.DataFrame([df['Crecimiento diario *'],\n",
    "              df['Crecimiento semanal *']]\n",
    "              ).transpose().to_csv('../../out/site/csv/data10.csv')\n",
    "\n",
    "### Por comuna\n",
    "\n",
    "### Histórico de casos ###\n",
    "pd.DataFrame(df.loc[:, df.columns.str.contains('Casos acumulados en')]\n",
    "              ).to_csv('../../out/site/csv/data11.csv')\n",
    "\n",
    "### Positividad ###\n",
    "pd.DataFrame(df.loc[:, df.columns.str.contains('Positividad') &\n",
    "                    ~df.columns.str.contains('diaria') &\n",
    "                    ~df.columns.str.contains('movil') &\n",
    "                    ~df.columns.str.contains('antigeno')]\n",
    "              ).to_csv('../../out/site/csv/data12.csv')\n",
    "\n",
    "### Activos ###\n",
    "pd.DataFrame(df.loc[:, df.columns.str.contains('activos') &\n",
    "                    ~df.columns.str.contains('confirmados') &\n",
    "                    ~df.columns.str.contains('probables')]\n",
    "              ).to_csv('../../out/site/csv/data13.csv')\n",
    "\n",
    "### Fallecidos no procesados por DEIS ###\n",
    "pd.DataFrame(df.loc[:, df.columns.str.contains('Fallecidos') \n",
    "      & ~df.columns.str.contains('Fallecidos confirmados')\n",
    "      & ~df.columns.str.contains('Fallecidos probables')]).to_csv('../../out/site/csv/data14.csv')\n",
    "\n",
    "### Fallecidos procesados por DEIS, confirmados ###\n",
    "pd.DataFrame(df.loc[:, df.columns.str.contains('Fallecidos') \n",
    "      & df.columns.str.contains('Fallecidos confirmados')\n",
    "      & ~df.columns.str.contains('Fallecidos probables')]).to_csv('../../out/site/csv/data15.csv')\n",
    "\n",
    "### Fallecidos procesados por DEIS, probables ###\n",
    "pd.DataFrame(df.loc[:, df.columns.str.contains('Fallecidos') \n",
    "      & ~df.columns.str.contains('Fallecidos confirmados')\n",
    "      & df.columns.str.contains('Fallecidos probables')]).to_csv('../../out/site/csv/data16.csv')\n",
    "\n",
    "### Red asistencial\n",
    "\n",
    "### UCI real y aproximada ###\n",
    "pd.DataFrame([df['UCI ocupacion media movil real'],\n",
    "              df['UCI ocupacion media movil aprox *']\n",
    "             ], index=['Media móvil real de ocupación UCI', 'Media móvil hipotética de ocupación UCI']\n",
    "              ).transpose().to_csv('../../out/site/csv/data17.csv')\n",
    "\n",
    "### Residencias sanitarias ###\n",
    "pd.DataFrame(df.loc[:, df.columns.str.contains('residencias') & ~df.columns.str.contains('Numero')]\n",
    "              ).to_csv('../../out/site/csv/data18.csv')\n",
    "\n",
    "### Detalle de muestra y otros datos segregados\n",
    "\n",
    "### PCR ###\n",
    "pd.DataFrame([df['PCR informados nuevos'],\n",
    "              df['PCR informados nuevos'].rolling(7).mean()\n",
    "             ], index=['PCR informados nuevos', 'Media móvil semanal de PCR informados nuevos']\n",
    "              ).transpose().to_csv('../../out/site/csv/data19.csv')\n",
    "\n",
    "### Antígeno ###\n",
    "pd.DataFrame([df['Antigenos informados nuevos'],\n",
    "              df['Antigenos informados nuevos'].rolling(7).mean()\n",
    "             ], index=['Antígenos informados nuevos', 'Media móvil semanal de antígenos informados nuevos']\n",
    "              ).transpose().to_csv('../../out/site/csv/data20.csv')\n",
    "\n",
    "### Detalle de casos nuevos ###\n",
    "pd.DataFrame([df['Casos nuevos con sintomas'],\n",
    "              df['Casos nuevos sin sintomas'],\n",
    "              df['Casos nuevos por laboratorio'],\n",
    "              df['Casos nuevos por antigeno']\n",
    "             ], index=['Casos nuevos con síntomas', 'Casos nuevos sin síntomas',\n",
    "                        'Casos nuevos por laboratorio', 'Casos nuevos por antígeno']\n",
    "              ).transpose().to_csv('../../out/site/csv/data21.csv')\n",
    "\n",
    "### Detalle de casos nuevos con sospecha de reinfección ###\n",
    "pd.DataFrame([df['Casos con sospecha de reinfeccion']\n",
    "             ], index=['Casos con sospecha de reinfección']\n",
    "              ).transpose().to_csv('../../out/site/csv/data22.csv')\n",
    "\n",
    "### Tasa de casos nuevos por cien mil habitantes en media móvil semanal ###\n",
    "pd.DataFrame([df['Tasa casos nuevos *']\n",
    "             ], index=['Tasa de casos nuevos de casos nuevos por cien mil habitantes']\n",
    "              ).transpose().to_csv('../../out/site/csv/data23.csv')\n",
    "\n",
    "### Tasa de activos ###\n",
    "pd.DataFrame([df['Tasa de activos (incidencia) *']\n",
    "             ], index=['Tasa de activos (incidencia)']\n",
    "              ).transpose().to_csv('../../out/site/csv/data24.csv')\n",
    "\n",
    "### Mortalidad específica ###\n",
    "pd.DataFrame([df['Mortalidad especifica *']\n",
    "             ], index=['Mortalidad específica por cien mil habitantes']\n",
    "              ).transpose().to_csv('../../out/site/csv/data25.csv')\n",
    "\n",
    "### Mortalidad específica por comuna ###\n",
    "pd.DataFrame(pd.DataFrame(df.loc[:, df.columns.str.contains('Mortalidad especifica comunal *')])\n",
    "              ).to_csv('../../out/site/csv/data26.csv')\n",
    "\n",
    "### Vacunación ###\n",
    "pd.DataFrame([df['Vacunados acumulados 1° dosis'], df['Vacunados acumulados 2° dosis'],\n",
    "              df['Vacunados acumulados unica dosis']]\n",
    "              ).transpose().to_csv('../../out/site/csv/data27.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reporte diario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Infografías generadas\n",
    "\n",
    "### Reporte diario ###\n",
    "\n",
    "### Cambios\n",
    "cambios = \"\"\"• Ninguno.\"\"\"\n",
    "\n",
    "### Fecha\n",
    "fecha_hoy = df.loc[weekend_data].name.strftime('%d de %B de %Y')\n",
    "\n",
    "### Casos nuevos confirmados y acumulados\n",
    "casos_hoy, consintomas_hoy, sinsintomas_hoy, porlaboratorio_hoy, casosacumulados_hoy, antigeno_hoy, reinfeccion_hoy = df['Casos nuevos'][weekend_data], df['Casos nuevos con sintomas'][weekend_data], df['Casos nuevos sin sintomas'][weekend_data], df['Casos nuevos por laboratorio'][weekend_data], df['Casos confirmados acumulados'][weekend_data], df['Casos nuevos por antigeno'][weekend_data], df['Casos con sospecha de reinfeccion'][weekend_data]\n",
    "\n",
    "### Casos recuperados nuevos y acumulados\n",
    "recuperados_hoy, recuperadosacumulados_hoy = df['Casos recuperados nuevos'][weekend_data], df['Casos recuperados acumulados'][weekend_data]\n",
    "\n",
    "### Casos fallecidos nuevos y acumulados\n",
    "fallecidosnuevos_hoy, fallecidosacumulados_hoy = df['Casos fallecidos nuevos'][weekend_data], df['Casos fallecidos acumulados'][weekend_data]\n",
    "\n",
    "### PCR informados nuevos y acumulados\n",
    "pcrnuevos_hoy, pcracumulados_hoy = df['PCR informados nuevos'][weekend_data], df['PCR informados acumulados'][weekend_data]\n",
    "\n",
    "### Residencias\n",
    "residenciasnumero_hoy, residenciasusuarios_hoy, residenciascupos_hoy = df['Numero de residencias'][weekend_data], df['Usuarios en residencias'][weekend_data], df['Cupos en residencias'][weekend_data]\n",
    "\n",
    "### Activos confirmados y probables\n",
    "activos_hoy, activosprobables_hoy = df['Casos activos confirmados'][weekend_data], df['Casos activos probables'][weekend_data]\n",
    "tasa_activos = df['Tasa de activos (incidencia) *'][weekend_data]\n",
    "\n",
    "### UCI diaria y ocupacion uci aproximada\n",
    "ucidiaria_hoy, uciaprox_hoy, errorabs_hoy = df['UCI ocupadas por confirmados'][weekend_data], round(df['UCI ocupacion media movil aprox *'][weekend_data], 1), round(df['UCI error abs *'][df['UCI error abs *'].last_valid_index()], 1)\n",
    "\n",
    "### Positividad diaria y móvil\n",
    "positividad_hoy, positividadmovil_hoy = df['Positividad diaria'][weekend_data], df['Positividad media movil *'][weekend_data]\n",
    "\n",
    "### Mortalidad especifica, Re, tasa casos nuevos y crecimiento\n",
    "me_hoy, reregional_hoy, tasanuevos_hoy = df['Mortalidad especifica *'][weekend_data], df['Re regional'][df['Re regional'].last_valid_index()], round(df['Tasa casos nuevos *'][weekend_data], 1)\n",
    "\n",
    "### Tendencia curva\n",
    "crecimientodiario_hoy = round(df['Crecimiento diario *'][weekend_data], 2)\n",
    "if (crecimientodiario_hoy < 1):\n",
    "    situacioncurva_hoy = \"curva de contagios a la baja\"\n",
    "else:\n",
    "    if (crecimientodiario_hoy == 1):\n",
    "        situacioncurva_hoy = \"curva de contagios sin cambios\"\n",
    "    else: \n",
    "        situacioncurva_hoy = \"curva de contagios al alza\"\n",
    "\n",
    "### Proceso de vacunación a población objetivo objetivo\n",
    "procesovacunacion_2dosis = int(round((df['Vacunados acumulados 2° dosis'][df['Vacunados acumulados 2° dosis'].last_valid_index()])/(poblacion_yomevacuno), 2)*100)\n",
    "procesovacunacion_unica = int(round((df['Vacunados acumulados unica dosis'][df['Vacunados acumulados unica dosis'].last_valid_index()])/(poblacion_yomevacuno), 2)*100)\n",
    "procesovacunacion_hoy = procesovacunacion_2dosis + procesovacunacion_unica\n",
    "procesovacunaciontotales_hoy = int(df['Vacunados acumulados 2° dosis'][df['Vacunados acumulados 2° dosis'].last_valid_index()]) + int(df['Vacunados acumulados unica dosis'][df['Vacunados acumulados unica dosis'].last_valid_index()])\n",
    "\n",
    "### Número de edición\n",
    "d1 = datetime.datetime(2020,6,27)\n",
    "d2 = datetime.datetime(2021,5,10)\n",
    "d3 = datetime.datetime(df.loc[weekend_data].name.year, \n",
    "                       df.loc[weekend_data].name.month, \n",
    "                       df.loc[weekend_data].name.day)\n",
    "ed_hoy = (d2 - d1).days + (d3 - d2).days\n",
    "ed_hoy = (d2 - d1).days + (d3 - d2).days\n",
    "\n",
    "### Valores de hoy a integer\n",
    "casos_hoy, consintomas_hoy, sinsintomas_hoy, porlaboratorio_hoy, casosacumulados_hoy, antigeno_hoy, reinfeccion_hoy, \\\n",
    "recuperados_hoy, recuperadosacumulados_hoy, \\\n",
    "fallecidosnuevos_hoy, fallecidosacumulados_hoy, \\\n",
    "pcrnuevos_hoy, pcracumulados_hoy, \\\n",
    "residenciasnumero_hoy, residenciasusuarios_hoy, residenciascupos_hoy, \\\n",
    "activos_hoy, activosprobables_hoy, \\\n",
    "ucidiaria_hoy, \\\n",
    "positividad_hoy, positividadmovil_hoy, \\\n",
    "me_hoy, procesovacunacion_hoy, procesovacunaciontotales_hoy,\\\n",
    "ed_hoy, tasa_activos = \\\n",
    "[ format(int(i), ',d') for i in [\n",
    "casos_hoy, consintomas_hoy, sinsintomas_hoy, porlaboratorio_hoy, casosacumulados_hoy, antigeno_hoy, reinfeccion_hoy, \\\n",
    "recuperados_hoy, recuperadosacumulados_hoy, \\\n",
    "fallecidosnuevos_hoy, fallecidosacumulados_hoy, \\\n",
    "pcrnuevos_hoy, pcracumulados_hoy, \\\n",
    "residenciasnumero_hoy, residenciasusuarios_hoy, residenciascupos_hoy, \\\n",
    "activos_hoy, activosprobables_hoy, \\\n",
    "ucidiaria_hoy, \\\n",
    "positividad_hoy, positividadmovil_hoy, \\\n",
    "me_hoy, procesovacunacion_hoy, procesovacunaciontotales_hoy,\\\n",
    "ed_hoy, tasa_activos]]\n",
    "\n",
    "### Datos de ayer ###\n",
    "\n",
    "### Casos nuevos confirmados y acumulados\n",
    "casos_ayer, consintomas_ayer, sinsintomas_ayer, porlaboratorio_ayer = df['Casos nuevos'][weekend_datay], df['Casos nuevos con sintomas'][weekend_datay], df['Casos nuevos sin sintomas'][weekend_datay], df['Casos nuevos por laboratorio'][weekend_datay]\n",
    "\n",
    "### Casos recuperados nuevos y acumulados\n",
    "recuperados_ayer = df['Casos recuperados nuevos'][weekend_datay]\n",
    "\n",
    "### Casos fallecidos nuevos y acumulados\n",
    "fallecidosnuevos_ayer = df['Casos fallecidos nuevos'][weekend_datay]\n",
    "\n",
    "### PCR informados nuevos y acumulados\n",
    "pcrnuevos_ayer = df['PCR informados nuevos'][weekend_datay]\n",
    "\n",
    "### Residencias\n",
    "residenciasusuarios_ayer = df['Usuarios en residencias'][weekend_datay]\n",
    "\n",
    "### Activos confirmados y probables\n",
    "activos_ayer, activosprobables_ayer = df['Casos activos confirmados'][weekend_datay], df['Casos activos probables'][weekend_datay]\n",
    "\n",
    "### UCI diaria y ocupacion uci aproximada\n",
    "ucidiaria_ayer = df['UCI ocupacion media movil aprox *'][weekend_datay]\n",
    "\n",
    "### Positividad diaria y móvil\n",
    "positividad_ayer = df['Positividad diaria'][weekend_datay]\n",
    "\n",
    "### Mortalidad especifica, Re y tasa casos nuevos\n",
    "me_ayer = df['Mortalidad especifica *'][weekend_datay]\n",
    "\n",
    "### Proceso de vacunación de población objetivo\n",
    "procesovacunacion_ayer_2 = (round((df['Vacunados acumulados 2° dosis'][df['Vacunados acumulados 2° dosis'].last_valid_index()-datetime.timedelta(days=1)])/(poblacion_yomevacuno), 2)*100)\n",
    "procesovacunacion_ayer_unica = (round((df['Vacunados acumulados unica dosis'][df['Vacunados acumulados unica dosis'].last_valid_index()-datetime.timedelta(days=1)])/(poblacion_yomevacuno), 2)*100)\n",
    "procesovacunacion_ayer = procesovacunacion_ayer_unica + procesovacunacion_ayer_2\n",
    "\n",
    "\n",
    "### Valores de ayer a integer\n",
    "casos_ayer, consintomas_ayer, sinsintomas_ayer, porlaboratorio_ayer, \\\n",
    "recuperados_ayer, \\\n",
    "fallecidosnuevos_ayer, \\\n",
    "pcrnuevos_ayer, \\\n",
    "residenciasusuarios_ayer, \\\n",
    "activos_ayer, activosprobables_ayer, \\\n",
    "ucidiaria_ayer, \\\n",
    "positividad_ayer, \\\n",
    "me_ayer, procesovacunacion_ayer\\\n",
    "= \\\n",
    "[ format(int(i), ',d') for i in [\n",
    "casos_ayer, consintomas_ayer, sinsintomas_ayer, porlaboratorio_ayer, \\\n",
    "recuperados_ayer, \\\n",
    "fallecidosnuevos_ayer, \\\n",
    "pcrnuevos_ayer, \\\n",
    "residenciasusuarios_ayer, \\\n",
    "activos_ayer, activosprobables_ayer, \\\n",
    "ucidiaria_ayer, \\\n",
    "positividad_ayer, \\\n",
    "me_ayer, procesovacunacion_ayer]]\n",
    "\n",
    "### Descripción\n",
    "desc1 = \\\n",
    "\"\"\"Reporte DIARIO, {} 🕑. \\n\n",
    "• Infectados {} casos nuevos de los cuales {} con síntomas, {} sin síntomas y {} sin notificar, dando un total de {} casos confirmados. Adicionalmente, {} casos nuevos confirmados por antígeno y {} casos totales con sospecha de reinfección. 🦠\n",
    "• Recuperadas {} personas, sumando {} recuperados totales. 💪\n",
    "• Perdieron la vida {} persona(s), sumando {} fallecidos totales. Nuestro profundo pésame a las familias. 🕊️\n",
    "• Informados {} exámenes PCR dando un total de {} exámenes PCR totales en la región. 🌡️\n",
    "• Respecto a residencias sanitarias, {} recintos de hospedaje con {} cupos, de los cuales {} están utilizados. 🏨\n",
    "• Se reportaron {} casos activos y {} activos probables. La tasa de activos (incidencia) es de {}. 🧪\n",
    "• La tasa de crecimiento es del {}: {}.\n",
    "• Hasta ayer, {} pacientes en unidad de cuidados intensivos con COVID-19 confirmado. Esto nos da una ocupación UCI media móvil semanal aproximada del {}% ± {}%. 🆘\n",
    "• La positividad de casos PCR fue del {}%. Asimismo, una positividad media móvil semanal del {}%. 😷\n",
    "• De cada cien mil habitantes en la región, {} fallecen por COVID-19. 😵\n",
    "• El Re Regional corresponde a {}. 💊\n",
    "• La tasa de casos nuevos (media móvil semanal por cien mil habitantes) corresponde a {}. 💦\n",
    "• En el proceso de vacunación, {}% vacunados de la población objetivo (al menos, {} personas con cuadro de vacunación completo). 💦\n",
    "\n",
    "*Fuente desde Min. de Ciencia y Tecnología, ICOVIDCHILE y @juancriolivares\n",
    "*La ocupación UCI es una aproximación de la situación de camas críticas regionales.\n",
    "*Datos actualizados hasta las 21 hrs. del día anterior.\n",
    "\n",
    "[ CAMBIOS EN LA {}° EDICION ⚙️ ]\n",
    "{}\n",
    "\n",
    "[ INFORMACIÓN ADICIONAL Y FE DE ERRATAS 🌌 ]\n",
    "• Reporte generado de forma automática. Si encuentras algún error o sugerencia, ¡comenta!\n",
    "• Autor: Alejandro Dinamarca.\n",
    "\n",
    "¡A cuidarse Tarapacá! 😉\"\"\".format(fecha_hoy, \\\n",
    "                                   casos_hoy, consintomas_hoy, sinsintomas_hoy, porlaboratorio_hoy, casosacumulados_hoy, antigeno_hoy, reinfeccion_hoy, \\\n",
    "                                   recuperados_hoy, recuperadosacumulados_hoy, \\\n",
    "                                   fallecidosnuevos_hoy, fallecidosacumulados_hoy, \\\n",
    "                                   pcrnuevos_hoy, pcracumulados_hoy, \\\n",
    "                                   residenciasnumero_hoy, residenciascupos_hoy, residenciasusuarios_hoy, \\\n",
    "                                   activos_hoy, activosprobables_hoy, tasa_activos, \\\n",
    "                                   crecimientodiario_hoy, situacioncurva_hoy, \\\n",
    "                                   ucidiaria_hoy, uciaprox_hoy, errorabs_hoy, \\\n",
    "                                   positividad_hoy, positividadmovil_hoy, \\\n",
    "                                   me_hoy, reregional_hoy, tasanuevos_hoy, procesovacunacion_hoy, procesovacunaciontotales_hoy,\\\n",
    "                                   ed_hoy, cambios)\n",
    "\n",
    "## Imprimimos\n",
    "print(desc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance de vacunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Balance vacunas ###\n",
    "\n",
    "### Cambios\n",
    "cambios = \"\"\"• Ninguno\"\"\"\n",
    "\n",
    "### Número de edición\n",
    "ed_vacuna = int(int(ed_hoy)/7 + 1)\n",
    "\n",
    "### Descripción\n",
    "desc2 = \\\n",
    "\"\"\"Balance VACUNAS, {}. 🕑 \n",
    "\n",
    "• El {}% de la población objetivo ha completado su proceso de vacunación en Tarapacá. El total es de {} personas con cuadros de vacunación completo.\n",
    "\n",
    "*Información proporcionada por Juan Cristobal Olivares (@juancriolivares), COVID-19 Vaccination.\n",
    "\n",
    "[ CAMBIOS EN LA {}° EDICION ⚙️ ]\n",
    "{}\n",
    "\n",
    "[ INFORMACIÓN ADICIONAL Y FE DE ERRATAS 🌌 ]\n",
    "• Reporte generado de forma automática. Si encuentras algún error o sugerencia, ¡comenta!\n",
    "• Autor: Alejandro Dinamarca.\n",
    "\n",
    "¡A cuidarse Tarapacá! 😉\n",
    "\"\"\".format(fecha_hoy, procesovacunacion_hoy, procesovacunaciontotales_hoy, ed_vacuna, cambios)\n",
    "\n",
    "## Imprimimos\n",
    "print(desc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indicador de fase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "### Ejecutamos notebook 2\n",
    "%run 2_thisistheway.ipynb\n",
    "\n",
    "### Ejecutamos notebook 3\n",
    "%run 3_thisistheway.ipynb\n",
    "\n",
    "### Ejecutamos notebook 4\n",
    "%run ./../4_legado/1_legado.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "### Cambios\n",
    "cambios = \"\"\"• Ninguno\"\"\"\n",
    "\n",
    "### Número de edición\n",
    "d1 = datetime.datetime(2020,9,4)\n",
    "d2 = datetime.datetime(2021,5,12)\n",
    "d3 = datetime.datetime(df.loc[weekend_data].name.year, \n",
    "                       df.loc[weekend_data].name.month, \n",
    "                       df.loc[weekend_data].name.day)\n",
    "ed_indicador = (d2 - d1).days/7.8 + (d3 - d2).days/7.8\n",
    "ed_indicador = (d2 - d1).days/7.8 + (d3 - d2).days/7.8\n",
    "ed_indicador = round(ed_indicador)\n",
    "\n",
    "### Descripción\n",
    "pred = 'Indicador FASE, {}. 🕑'.format(fecha_hoy)\n",
    "for result in results:\n",
    "    pred += '\\n' + result\n",
    "\n",
    "pred += \"\"\"\n",
    "\n",
    "[ CAMBIOS EN LA {}° EDICION ⚙️ ]\n",
    "\n",
    "{}\n",
    "\n",
    "[ INFORMACIÓN ADICIONAL Y FE DE ERRATAS 🌌 ]\n",
    "\n",
    "• Reporte generado de forma automática. Si encuentras algún error o sugerencia, ¡comenta!\n",
    "\n",
    "• Autor: Alejandro Dinamarca.\n",
    "\n",
    "• Para mayor información del funcionamiento del algoritmo, visitar el sitio adinamarca.github.io\n",
    "\n",
    "¡A cuidarse Tarapacá! 😉\n",
    "\"\"\".format(ed_indicador, cambios)\n",
    "\n",
    "display(Markdown(pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graficando\n",
    "\n",
    "---\n",
    "\n",
    "La mejor forma de resumir y entender la tendencia de datos es a partir de un gráfico. Un buen gráfico debe ser capaz de narrar sin complejizar, y por ello, son fundamentales en el data storytelling (que los datos den a conocer una historia). En este sentido, graficaremos con Matplotlib.\n",
    "\n",
    "<center><a href=\"https://matplotlib.org/\"><img src=\"https://matplotlib.org/_static/logo2_compressed.svg\"></img></a></center>\n",
    "\n",
    "Existen otras librerías, como Seaborn (sns), que nos permite realizar gráficos más avanzados que Matplotlib con una sintaxis más simple. Sin embargo, Matplotlib tiene mayor versatilidad, y por ello, lo utilizaremos sobre Seaborn (sns viene con una sintaxis más simple pero menos manejable).\n",
    "\n",
    "<center><a href=\"https://seaborn.pydata.org/\"><img src=\"https://seaborn.pydata.org/_static/logo-wide-lightbg.svg\"></img></a></center>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reporte diario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Graficando para reporte diario ###\n",
    "\n",
    "### Para gráficos de torta\n",
    "class graphPie:\n",
    "    \"\"\"\n",
    "    Clase para gráfico de torta.\n",
    "    Args\n",
    "    ____\n",
    "    data: datos para torta\n",
    "    color: colores\n",
    "    path: dirección de guardado\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, data, color, path):\n",
    "        fig, ax = plt.subplots(figsize=(1.5, 1.5), subplot_kw=dict(aspect=\"equal\"))\n",
    "        self.data = data\n",
    "        self.color = color\n",
    "        def absolute_value(val):\n",
    "            a = np.int(np.round(val/100*(np.array(data).sum())))\n",
    "            return a\n",
    "        graph = plt.pie(self.data, autopct=absolute_value, shadow=True, colors=self.color, pctdistance=0.9, textprops={'color':'w', 'fontsize': 9}, explode=[0.02, 0.02, 0.02])\n",
    "        self.path = path\n",
    "        plt.savefig(self.path)\n",
    "        plt.show()\n",
    "        print('Gráfico guardado.')\n",
    "\n",
    "### Para gráficos de línea\n",
    "class graphLine:\n",
    "    \"\"\"\n",
    "    Clase para gráfico de barra.\n",
    "    Args\n",
    "    ____\n",
    "    x: eje x\n",
    "    y: eje y\n",
    "    color: colores\n",
    "    path: dirección de guardado\n",
    "    opt: sufijo de dato\n",
    "    line: línea paralela a y, ''=True, '#'=False\n",
    "    liney: valor para line\n",
    "    txth: texto, ''=True, '#'=False\n",
    "    txt_str: string para txth\n",
    "    txtx: x para txth\n",
    "    txty: y para txth\n",
    "    txts: tamaño para txt\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, x, y, color, path, opt='', line='#', liney=1, txth='#', txt_str='', txtx=1, txty=1, txts=20):\n",
    "        self.opt = opt\n",
    "        self.s = 0\n",
    "        fig, ax = plt.subplots(figsize=(4, 3))\n",
    "        ax.spines['bottom'].set_color('white')\n",
    "        ax.spines['left'].set_color('white')\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.line = line\n",
    "        self.liney = liney\n",
    "        self.txth = txth\n",
    "        self.txt_str = txt_str\n",
    "        self.txtx = txtx\n",
    "        self.txty = txty\n",
    "        self.txts = txts\n",
    "        self.color = color\n",
    "        self.path = path\n",
    "        for x in self.x:\n",
    "            graph = plt.plot(self.x[self.s], self.y[self.s], color=self.color[self.s])\n",
    "            for i,j in zip(self.x[self.s],self.y[self.s]):\n",
    "                ax.annotate('{}{}'.format(int(j), self.opt),xy=(i,j), color='w', size=8, horizontalalignment='center', verticalalignment='bottom')\n",
    "            exec('{}plt.axhline(self.liney, color=\"white\")'.format(self.line))\n",
    "            exec('{}ax.text(txtx, txty, txt_str, color=\"white\", size=self.txts)'.format(self.txth))\n",
    "            self.s += 1\n",
    "        ax.tick_params(labelsize=3, colors='w', grid_color='w')\n",
    "        self.path = path\n",
    "        plt.savefig(self.path)\n",
    "        ax.tick_params(colors='#000', grid_color='#000')\n",
    "        ax.spines['bottom'].set_color('#000')\n",
    "        ax.spines['left'].set_color('#000')\n",
    "        plt.show()\n",
    "        print('Gráfico guardado.')\n",
    "\n",
    "### Primer gráfico: Detalle de casos nuevos\n",
    "graph1 = graphPie([df['Casos nuevos con sintomas'][weekend_data], df['Casos nuevos sin sintomas'][weekend_data], df['Casos nuevos por laboratorio'][weekend_data]], \\\n",
    "         ['#a688f1', '#ca6e8f', '#a8ca55'], '../../in/diario/grafico/1.png')\n",
    "\n",
    "### Segundo gráfico: Balance diario\n",
    "graph2 = graphPie([df['Casos nuevos'][weekend_data], df['Casos recuperados nuevos'][weekend_data], df['Casos fallecidos nuevos'][weekend_data]], \\\n",
    "         ['#b68b41', '#43bb48', '#fe4747'], '../../in/diario/grafico/2.png')\n",
    "\n",
    "\n",
    "### Tercer gráfico: Balance semanal\n",
    "graph3 = graphLine([df[weekstart_data:weekend_data].index]*3,\\\n",
    "                   [df['Casos nuevos'][weekstart_data:weekend_data], df['Casos recuperados nuevos'][weekstart_data:weekend_data], df['Casos fallecidos nuevos'][weekstart_data:weekend_data]], \\\n",
    "                   color=['#b68b40', '#43bb47', '#fe4747'], \\\n",
    "                   path='../../in/diario/grafico/3.png')\n",
    "\n",
    "### Cuarto gráfico: Activos semanales\n",
    "graph4 = graphLine([df[weekstart_data:weekend_data].index]*2,\\\n",
    "                   [df['Casos activos confirmados'][weekstart_data:weekend_data], df['Casos activos probables'][weekstart_data:weekend_data]], \\\n",
    "                   color=['#edf01c', '#9585dc'], \\\n",
    "                   path='../../in/diario/grafico/4.png',)\n",
    "\n",
    "## Quinto gráfico: Positividad\n",
    "graph5 = graphLine([df[weekstart_data:weekend_data].index]*2,\\\n",
    "                   [df['Positividad diaria'][weekstart_data:weekend_data], df['Positividad media movil *'][weekstart_data:weekend_data]], \\\n",
    "                   color=['#f052d0', '#f5e7d0'], \\\n",
    "                   path='../../in/diario/grafico/5.png', opt='%')\n",
    "\n",
    "### Sexto gráfico: Residencias sanitarias\n",
    "graph6 = graphLine([df[weekstart_data:weekend_data].index]*2,\\\n",
    "                   [df['Cupos en residencias'][weekstart_data:weekend_data], df['Usuarios en residencias'][weekstart_data:weekend_data]], \\\n",
    "                   color=['#4c4c4c', '#1efde2'], \\\n",
    "                   path='../../in/diario/grafico/6.png')\n",
    "    \n",
    "### ¿Todo ok?\n",
    "print('\\n \\n Gráficos del reporte diario guardados de forma exitosa.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance de vacunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Graficando para balance vacunas ###\n",
    "\n",
    "### Últimas cifras de vacunación a población total/objetivo\n",
    "pob_total = np.array([df['Vacunados acumulados 1° dosis'][df['Vacunados acumulados 1° dosis'].last_valid_index()], \\\n",
    "          df['Vacunados acumulados 2° dosis'][df['Vacunados acumulados 2° dosis'].last_valid_index()] + df['Vacunados acumulados unica dosis'][df['Vacunados acumulados unica dosis'].last_valid_index()], \\\n",
    "          poblacion - df['Vacunados acumulados 2° dosis'][df['Vacunados acumulados 2° dosis'].last_valid_index()] + df['Vacunados acumulados unica dosis'][df['Vacunados acumulados unica dosis'].last_valid_index()]])\n",
    "pob_obj = np.array([df['Vacunados acumulados 1° dosis'][df['Vacunados acumulados 1° dosis'].last_valid_index()], \\\n",
    "          df['Vacunados acumulados 2° dosis'][df['Vacunados acumulados 2° dosis'].last_valid_index()] + df['Vacunados acumulados unica dosis'][df['Vacunados acumulados unica dosis'].last_valid_index()], \\\n",
    "          poblacion_yomevacuno - df['Vacunados acumulados 2° dosis'][df['Vacunados acumulados 2° dosis'].last_valid_index()] + df['Vacunados acumulados unica dosis'][df['Vacunados acumulados unica dosis'].last_valid_index()]])\n",
    "labels = np.array(['Con 1° dosis \\n (sin inmunidad o parcial)', 'Con cuadro completo \\n (eventual inmunes)', 'Sin cuadro completo \\n (sin inmunidad)'])\n",
    "vacunacion_pct = pd.DataFrame([pob_total, pob_obj]).transpose()\n",
    "vacunacion_pct.index = labels\n",
    "vacunacion_pct.columns = ['Población total', 'Población objetivo']\n",
    "\n",
    "### Para gráficos de barra\n",
    "class graphBar:\n",
    "    \"\"\"\n",
    "    Clase para gráfico de barra.\n",
    "    Args\n",
    "    ____\n",
    "    x: eje x\n",
    "    y: eje y\n",
    "    color: colores\n",
    "    path: dirección de guardado\n",
    "    alpha: transparencia\n",
    "    opt:'' sufijo de dato\n",
    "    uni:0 booleano (0 para color para todas las barras, 1 para color por cada barra)\n",
    "    w:4 (ancho)\n",
    "    l:3 (largo)\n",
    "    horizontal:0 (gráfico vertical u horizontal)\n",
    "    rot: rotacion para gráfico con uni=1\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, x, y, color, path, alpha, opt='', uni=0, w=4, l=3, horizontal=0, rot=0):\n",
    "        self.opt = opt\n",
    "        self.w = 4\n",
    "        self.l = 3\n",
    "        self.s = 0\n",
    "        fig, ax = plt.subplots(figsize=(w, l))\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.color = color\n",
    "        self.alpha = alpha\n",
    "        self.path = path\n",
    "        self.uni = uni\n",
    "        self.horizontal = 0\n",
    "        self.rot = rot\n",
    "        if horizontal == 0:\n",
    "            if uni == True:\n",
    "                for x in self.x:\n",
    "                    ax.bar(self.x[self.s], self.y[self.s], color=self.color, alpha=self.alpha[self.s])\n",
    "                for i,j in zip(self.x[self.s],self.y[self.s]):\n",
    "                    ax.annotate('{}{}'.format(format(int(j), ',d'), self.opt),xy=(i,j), color='w', size=9, horizontalalignment='center', verticalalignment='bottom')\n",
    "                self.s += 1\n",
    "                plt.xticks(rotation=self.rot)\n",
    "            else:\n",
    "                for x in self.x:\n",
    "                    ax.bar(self.x[self.s], self.y[self.s], color=self.color[self.s], alpha=self.alpha[self.s])\n",
    "                    for i,j in zip(self.x[self.s],self.y[self.s]):\n",
    "                        ax.annotate('{}{}'.format(format(int(j), ',d'), self.opt),xy=(i,j), color='w', size=4.5, horizontalalignment='center', verticalalignment='bottom')\n",
    "                    self.s += 1\n",
    "                    plt.xticks(rotation=15)\n",
    "        else:\n",
    "            for x in self.x:\n",
    "                ax.barh(width=self.x[self.s], y=self.y[self.s], color=self.color[self.s], alpha=self.alpha[self.s])\n",
    "                ax.axis('off')\n",
    "                fig.patch.set_visible(True)\n",
    "                self.s += 1\n",
    "        ax.tick_params(labelsize=5, colors='w', grid_color='w')\n",
    "        ax.get_yaxis().set_major_formatter(\n",
    "        mpl.ticker.FuncFormatter(lambda y, p: format(int(y), ',d')))\n",
    "        self.path = path\n",
    "        ax.spines['bottom'].set_color('white')\n",
    "        ax.spines['left'].set_color('white')\n",
    "        plt.savefig(self.path, bbox_inches = 'tight')\n",
    "        ax.tick_params(colors='#000', grid_color='#000')\n",
    "        ax.spines['bottom'].set_color('#000')\n",
    "        ax.spines['left'].set_color('#000')\n",
    "        plt.show()\n",
    "        print('Gráfico guardado.')\n",
    "        \n",
    "### Primer gráfico: Proporción objetivo vacunada\n",
    "graph1 = graphBar([[100], [int(procesovacunacion_hoy)]],\\\n",
    "                   [[0], [0]], \\\n",
    "                   color=['gray', '#9ad5ff'], alpha=[1, 1], \\\n",
    "                   path='../../in/vacuna/grafico/1.png', uni=1, w=1.68, l=0.6, horizontal=1)\n",
    "vaccine = Image.open(requests.get('https://raw.githubusercontent.com/pandemiaventana/pandemiaventana/main/in/vacuna/grafico/vaccine.png', stream=True).raw).rotate(-90)\n",
    "pct_ = Image.open('../../in/vacuna/grafico/1.png')\n",
    "background = Image.new('RGBA', (1000, 1000), (0, 0, 0, 0))\n",
    "background.paste(pct_, (135,359), pct_)\n",
    "background.paste(vaccine, (0, 0), vaccine)\n",
    "background = background.rotate(90).resize((400, 700), Image.ANTIALIAS)\n",
    "background.save('../../in/vacuna/grafico/1.png')\n",
    "\n",
    "### Segundo gráfico: Vacunas administradas (1° dosis)\n",
    "graph2 = graphBar([vacunacion_pct.index],\\\n",
    "                   [vacunacion_pct['Población total']], \\\n",
    "                   color=['#8899e1', '#9ad5ff', 'gray'], alpha=[1], \\\n",
    "                   path='../../in/vacuna/grafico/2.png', uni=1, w=3.5, l=2.5)\n",
    "        \n",
    "### Tercer gráfico: Vacunas administradas (1° dosis)\n",
    "graph3 = graphBar([vacunacion_pct.index],\\\n",
    "                   [vacunacion_pct['Población objetivo']], \\\n",
    "                   color=['#8899e1', '#9ad5ff', 'gray'], alpha=[1], \\\n",
    "                   path='../../in/vacuna/grafico/3.png', uni=1, w=3.5, l=2.5)\n",
    "        \n",
    "### Cuarto gráfico: Vacunas administradas (1° dosis)\n",
    "graph4 = graphBar([vacunacion_etaria.index]*2,\\\n",
    "                   [vacunacion_etaria['Poblacion'], vacunacion_etaria['1° Dosis']], \\\n",
    "                   color=['gray', '#8899e1'], alpha=[0.9, 0.9], w=3.5, l=2.5, \\\n",
    "                   path='../../in/vacuna/grafico/4.png')\n",
    "\n",
    "### Quinto gráfico: Vacunas administradas (2° dosis)\n",
    "graph5 = graphBar([vacunacion_etaria.index]*2,\\\n",
    "                   [vacunacion_etaria['Poblacion'], vacunacion_etaria['2° Dosis'] + vacunacion_etaria['Unica dosis']], \\\n",
    "                   color=['gray', '#9ad5ff'], alpha=[0.9, 0.9], w=3.5, l=2.5, \\\n",
    "                   path='../../in/vacuna/grafico/5.png')\n",
    "\n",
    "### ¿Todo ok?\n",
    "print('\\n \\n Gráficos del balance de vacunas guardados de forma exitosa.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indicador de fase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Graficando para indicador fase ###\n",
    "\n",
    "### Primer gráfico: Días por fase por comuna\n",
    "graph1 = graphBar([df.loc[:, df.columns.str.contains('Paso a Paso (dias)', regex=False)].columns.str[19:]],\\\n",
    "                   [df.loc[:, df.columns.str.contains('Paso a Paso (dias)', regex=False)].loc[pasopaso_comuna.index[-1]]], \\\n",
    "                   color=resultado_colores, alpha=[1], \\\n",
    "                   path='../../in/indicadorfase/grafico/1.png', uni=1, w=3.5, l=2.5, rot=15)\n",
    "\n",
    "### Segundo gráfico: Activos al último informe epidemiológico por comuna\n",
    "graph2 = graphBar([df.loc[:, df.columns.str.contains('Paso a Paso (dias)', regex=False)].columns.str[19:]],\\\n",
    "                   [(df.loc[:, df.columns.str.contains('Casos activos en')].\n",
    "loc[casoscomuna_activos.last_valid_index()].reset_index(drop=True).divide(poblaciones_comunales)*100000)[:7]], \\\n",
    "                   color=resultado_colores + ['white'], alpha=[1], \\\n",
    "                   path='../../in/indicadorfase/grafico/2.png', uni=1, w=3.5, l=2.5, rot=15)\n",
    "\n",
    "### Tercer gráfico: Fallecidos al último informe epidemiológico por comuna\n",
    "graph3 = graphBar([df.loc[:, df.columns.str.contains('confirmados DEIS', regex=False)].columns.str[28:]],\\\n",
    "                   [df.loc[:, df.columns.str.contains('confirmados DEIS', regex=False)].loc\n",
    "                    [casoscomuna_activos.index[-1]].reset_index(drop=True).divide(poblaciones_comunales)*100000], \\\n",
    "                   color=resultado_colores, alpha=[1], \\\n",
    "                   path='../../in/indicadorfase/grafico/3.png', uni=1, w=3.5, l=2.5, rot=15)\n",
    "\n",
    "### Cuarto gráfico: Notificación PCR por comuna\n",
    "graph4 = graphBar([df.loc[:, df.columns.str.contains('Notificacion PCR', regex=False)].columns.str[17:]],\\\n",
    "                   [df.loc[:, df.columns.str.contains('Notificacion PCR ', regex=False)]\n",
    "                    .loc[positividad_comuna.last_valid_index()].reset_index(drop=True).divide(poblaciones_comunales)*100000], \\\n",
    "                   color=resultado_colores, alpha=[1], \\\n",
    "                   path='../../in/indicadorfase/grafico/4.png', uni=1, w=3.5, l=2.5, rot=15)\n",
    "\n",
    "### Quinto gráfico: Casos acumulados por comuna\n",
    "graph5 = graphBar([df.loc[:, df.columns.str.contains('Casos acumulados en', regex=False)].columns.str[20:][:7]],\\\n",
    "                   [(df.loc[:, df.columns.str.contains('Casos acumulados en')].\n",
    "loc[casoscomuna_activos.last_valid_index()].reset_index(drop=True).divide(poblaciones_comunales)*100000)[:7]], \\\n",
    "                   color=resultado_colores, alpha=[1], \\\n",
    "                   path='../../in/indicadorfase/grafico/5.png', uni=1, w=3.5, l=2.5, rot=15)\n",
    "\n",
    "### Sexto gráfico: Positividad por comuna\n",
    "graph6 = graphBar([df.loc[:, df.columns.str.contains('Paso a Paso (dias)', regex=False)].columns.str[19:]],\\\n",
    "                   [df.loc[:, df.columns.str.contains('Positividad ', regex=False) & \n",
    "                   ~df.columns.str.contains('diaria', regex=False) &\n",
    "                   ~df.columns.str.contains('movil', regex=False) &\n",
    "                   ~df.columns.str.contains('antigeno', regex=False)].loc[positividad_comuna.last_valid_index()]], \\\n",
    "                   color=resultado_colores + ['white'], alpha=[1], \\\n",
    "                   path='../../in/indicadorfase/grafico/6.png', uni=1, w=3.5, l=2.5, rot=15, opt='%')\n",
    "\n",
    "### Séptimo gráfico: BAC por comuna\n",
    "graph7 = graphBar([df.loc[:, df.columns.str.contains('BAC', regex=False)].columns.str[4:]],\\\n",
    "                   [df.loc[:, df.columns.str.contains('BAC ', regex=False)].loc[positividad_comuna.last_valid_index()]], \\\n",
    "                   color=resultado_colores, alpha=[1], \\\n",
    "                   path='../../in/indicadorfase/grafico/7.png', uni=1, w=3.5, l=2.5, rot=15, opt='%')\n",
    "\n",
    "### ¿Todo ok?\n",
    "print('\\n \\n Gráficos del indicador de fase guardados de forma exitosa.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Toque de queda\n",
    "avance_graph = (df['Vacunados acumulados 2° dosis'][-14:]\n",
    "                         + df['Vacunados acumulados unica dosis'][-14:])/poblacion_yomevacuno*100\n",
    "avance_graph = avance_graph[avance_graph.first_valid_index():avance_graph.last_valid_index()]\n",
    "\n",
    "\n",
    "## Primer gráfico: tasa de activos\n",
    "graph1 = graphLine([df[-14:].index],\\\n",
    "                   [df['Tasa de activos (incidencia) *'][-14:]], \\\n",
    "                   color=['tab:orange'], \\\n",
    "                   path='../../in/toquequeda/grafico/1.png', line='', liney=150,\n",
    "                   txth='', txt_str='Umbral para toque de queda (menor a 150)', txtx=avance_graph.first_valid_index(),\n",
    "                  txty=147, txts=6)\n",
    "\n",
    "## Segundo gráfico: avance vacunación\n",
    "\n",
    "graph2 = graphLine([avance_graph.index],\\\n",
    "                   [avance_graph], \\\n",
    "                   color=['tab:cyan'], \\\n",
    "                   path='../../in/toquequeda/grafico/2.png', opt='%', line='', liney=80,\n",
    "                   txth='', txt_str='Umbral para toque de queda (mayor al 80%)', txtx=avance_graph.first_valid_index(),\n",
    "                  txty=79.2, txts=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generando reportes\n",
    "\n",
    "---\n",
    "\n",
    "Teniendo la información recopilada, nos basaremos en el <a href=\"https://automatetheboringstuff.com/chapter17/\">capítulo 17 de manipular imágenes con Python, de @AlSweigart</a> {footcite}``AlSweigart`` para generar las infografías.\n",
    "\n",
    "El procedimiento manual implicaba exportar archivos .JSON, y a partir de ellos, rellenar manualmente los datos y gráficos en Photoshop, lo que es un proceso tedioso, y altamente susceptible a equivocaciones. \n",
    "\n",
    "Debido al párrafo anterior, se intentará automatizar el mismo procedimiento, pero a través de Python, dado que son pasos mecánicos gracias a {cite}``AlSweigart``.\n",
    "\n",
    "Lo que tenemos que realizar consistirá en los siguientes pasos:\n",
    "\n",
    "- Rellenar con datos las infografías prediseñadas en Photoshop.\n",
    "\n",
    "- Colocar imágenes de gráficos según corresponda en las mismas infografías.\n",
    "\n",
    "- Exportar.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reporte diario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Generando reporte diario ###\n",
    "\n",
    "### Abriendo gráficos guardados\n",
    "x = range(1, 7)\n",
    "for i in x:\n",
    "    image_path = '../../in/diario/grafico/{}.png'.format(i)\n",
    "    exec('graph{} = Image.open(image_path)'.format(i))\n",
    "    i += i\n",
    "\n",
    "### Cargando imagenes\n",
    "x = range(1, 11)\n",
    "for i in x:\n",
    "    image_path = '../../in/diario/{}.png'.format(i)\n",
    "    exec('diario_{} = Image.open(image_path)'.format(i))\n",
    "    exec('diario{} = diario_{}.copy()'.format(i, i))\n",
    "    i += i\n",
    "    \n",
    "### Cargando texto (gracias a Google Fonts y shoes)\n",
    "roboto = requests.get(\"https://github.com/googlefonts/roboto/raw/main/src/hinted/Roboto-Regular.ttf\")\n",
    "coolvetica = requests.get(\"https://github.com/shoes/brown_shoes/blob/main/fonts/Coolvetica.ttf?raw=true\")\n",
    "roboto_ed = ImageFont.truetype(BytesIO(roboto.content), 50)\n",
    "roboto_data0 = ImageFont.truetype(BytesIO(roboto.content), 20)\n",
    "roboto_data1 = ImageFont.truetype(BytesIO(roboto.content), 28)\n",
    "roboto_data2 = ImageFont.truetype(BytesIO(roboto.content), 30)\n",
    "roboto_data3 = ImageFont.truetype(BytesIO(roboto.content), 40)\n",
    "coolvetica_data0 = ImageFont.truetype(BytesIO(coolvetica.content), 43)\n",
    "coolvetica_data1 = ImageFont.truetype(BytesIO(coolvetica.content), 75)\n",
    "coolvetica_data2 = ImageFont.truetype(BytesIO(coolvetica.content), 135)\n",
    "coolvetica_data3 = ImageFont.truetype(BytesIO(coolvetica.content), 100)\n",
    "coolvetica_data4 = ImageFont.truetype(BytesIO(coolvetica.content), 180)\n",
    "\n",
    "### Manipulando primera imagen\n",
    "txt = ImageDraw.Draw(diario1)\n",
    "\n",
    "### Textos\n",
    "txt.text((860, 35), '{}° ed.'.format(ed_hoy), fill='#b9b9b9', font=roboto_ed) # edicion\n",
    "txt.text((380, 357), '{}'.format(df.loc[weekend_data].name.strftime('%d/%m/%Y')), fill='#fff', font=roboto_data1) # fecha\n",
    "txt.text((650, 435), '{}'.format(casos_hoy), fill='#dfdede', font=coolvetica_data1) # casos nuevos\n",
    "txt.text((820, 510), '{}'.format(recuperados_hoy), fill='#dfdede', font=coolvetica_data1) # recuperados nuevos\n",
    "txt.text((745, 585), '{}'.format(fallecidosnuevos_hoy), fill='#dfdede', font=coolvetica_data1) # fallecidos nuevos\n",
    "txt.text((825, 660), '{}'.format(activos_hoy), fill='#dfdede', font=coolvetica_data1) # activos\n",
    "txt.text((760, 735), '{}'.format(activosprobables_hoy), fill='#dfdede', font=coolvetica_data1) # activos probables\n",
    "txt.text((700, 810), '{}'.format(pcrnuevos_hoy), fill='#dfdede', font=coolvetica_data1) # pcr nuevos\n",
    "txt.text((695, 890), '{}%'.format(positividad_hoy), fill='#dfdede', font=coolvetica_data1) # positividad diaria\n",
    "txt.text((750, 965), '{}'.format(residenciasusuarios_hoy), fill='#dfdede', font=coolvetica_data1) # residencias sanitarias\n",
    "txt.text((725, 1035), '{}'.format(ucidiaria_hoy), fill='#dfdede', font=coolvetica_data1) # uci diaria\n",
    "\n",
    "### Guardamos\n",
    "diario1.save('../../out/diario/1.png')\n",
    "\n",
    "### Manipulando segunda imagen\n",
    "txt = ImageDraw.Draw(diario2)\n",
    "\n",
    "### Textos (a diferencia de los textos anteriores, debemos centrar a medida se añaden carácteres con 'anchor')\n",
    "txt.text((190, 680), '{}'.format(consintomas_hoy), fill='#dfdede', font=coolvetica_data2, anchor='ms') # casos con sintomas\n",
    "txt.text((190, 750), 'Ayer: {}'.format(consintomas_ayer), fill='#989898', font=roboto_data3, anchor='ms') # ayer, casos con sintomas\n",
    "txt.text((540, 680), '{}'.format(sinsintomas_hoy), fill='#dfdede', font=coolvetica_data2, anchor='ms') # casos sin sintomas\n",
    "txt.text((540, 750), 'Ayer: {}'.format(sinsintomas_ayer), fill='#989898', font=roboto_data3, anchor='ms') # ayer, casos sin sintomas\n",
    "txt.text((890, 680), '{}'.format(porlaboratorio_hoy), fill='#dfdede', font=coolvetica_data2, anchor='ms') # casos por laboratorio\n",
    "txt.text((890, 750), 'Ayer: {}'.format(porlaboratorio_ayer), fill='#989898', font=roboto_data3, anchor='ms') # ayer, casos por laboratorio\n",
    "txt.text((350, 910), '{} casos nuevos confirmados por antígeno.'.format(antigeno_hoy), fill='#b9b9b9', font=roboto_data1) # nuevos antigeno\n",
    "txt.text((350, 960), '{} casos del total están con sospecha de reinfección.'.format(reinfeccion_hoy), fill='#b9b9b9', font=roboto_data1) # reinfeccion\n",
    " \n",
    "### Gráficos\n",
    "diario2.paste(graph1, (570, 50), graph1)\n",
    "\n",
    "### Guardamos\n",
    "diario2.save('../../out/diario/2.png')\n",
    "\n",
    "### Manipulando tercera imagen\n",
    "txt = ImageDraw.Draw(diario3)\n",
    "\n",
    "### Textos\n",
    "txt.text((190, 680), '{}'.format(casos_hoy), fill='#dfdede', font=coolvetica_data2, anchor='ms') # casos con sintomas\n",
    "txt.text((190, 750), 'Ayer: {}'.format(casos_ayer), fill='#989898', font=roboto_data3, anchor='ms') # ayer, casos con sintomas\n",
    "txt.text((540, 680), '{}'.format(recuperados_hoy), fill='#dfdede', font=coolvetica_data2, anchor='ms') # casos sin sintomas\n",
    "txt.text((540, 750), 'Ayer: {}'.format(recuperados_ayer), fill='#989898', font=roboto_data3, anchor='ms') # ayer, casos sin sintomas\n",
    "txt.text((890, 680), '{}'.format(fallecidosnuevos_hoy), fill='#dfdede', font=coolvetica_data2, anchor='ms') # casos por laboratorio\n",
    "txt.text((890, 750), 'Ayer: {}'.format(fallecidosnuevos_ayer), fill='#989898', font=roboto_data3, anchor='ms') # ayer, casos por laboratorio\n",
    "txt.text((190, 860), 'Acumulado: {}'.format(casosacumulados_hoy), fill='#989898', font=roboto_data1, anchor='ms') # nuevos antigeno\n",
    "txt.text((540, 860), 'Acumulado: {}'.format(recuperadosacumulados_hoy), fill='#989898', font=roboto_data1, anchor='ms') # reinfeccion\n",
    "txt.text((890, 860), 'Acumulado: {}'.format(fallecidosacumulados_hoy), fill='#989898', font=roboto_data1, anchor='ms') # reinfeccion\n",
    "\n",
    "### Gráficos\n",
    "diario3.paste(graph2, (570, 50), graph2)\n",
    "\n",
    "### Guardamos\n",
    "diario3.save('../../out/diario/3.png')\n",
    "\n",
    "### Manipulando cuarta imagen\n",
    "txt = ImageDraw.Draw(diario4)\n",
    "\n",
    "### Textos\n",
    "txt.text((780, 70), '{}'.format(reregional_hoy), fill='#dfdede', font=coolvetica_data2) # casos con sintomas\n",
    "txt.text((190, 680), '{}'.format(pcrnuevos_hoy), fill='#dfdede', font=coolvetica_data2, anchor='ms') # casos con sintomas\n",
    "txt.text((190, 750), 'Ayer: {}'.format(pcrnuevos_ayer), fill='#989898', font=roboto_data3, anchor='ms') # ayer, casos con sintomas\n",
    "txt.text((540, 680), '{}'.format(residenciasusuarios_hoy), fill='#dfdede', font=coolvetica_data2, anchor='ms') # casos sin sintomas\n",
    "txt.text((540, 750), 'Ayer: {}'.format(residenciasusuarios_ayer), fill='#989898', font=roboto_data3, anchor='ms') # ayer, casos sin sintomas\n",
    "txt.text((890, 680), '{}'.format(activos_hoy), fill='#dfdede', font=coolvetica_data2, anchor='ms') # casos por laboratorio\n",
    "txt.text((890, 750), 'Ayer: {}'.format(activos_ayer), fill='#989898', font=roboto_data3, anchor='ms') # ayer, casos por laboratorio\n",
    "txt.text((190, 860), 'Acumulado: {}'.format(pcracumulados_hoy), fill='#989898', font=roboto_data1, anchor='ms') # nuevos antigeno\n",
    "txt.text((540, 860), 'Establecimientos: {}'.format(residenciasnumero_hoy), fill='#989898', font=roboto_data1, anchor='ms') # reinfeccion\n",
    "txt.text((890, 860), 'Incidencia: {}'.format(tasa_activos), fill='#989898', font=roboto_data1, anchor='ms') # reinfeccion\n",
    "\n",
    "### Guardamos\n",
    "diario4.save('../../out/diario/4.png')\n",
    "\n",
    "### Manipulando quinta imagen\n",
    "txt = ImageDraw.Draw(diario5)\n",
    "\n",
    "### Textos\n",
    "txt.text((780, 70), '{}%'.format(positividadmovil_hoy), fill='#dfdede', font=coolvetica_data2) # casos con sintomas\n",
    "txt.text((190, 680), '{}%'.format(positividad_hoy), fill='#dfdede', font=coolvetica_data2, anchor='ms') # casos con sintomas\n",
    "txt.text((190, 750), 'Ayer: {}%'.format(positividad_ayer), fill='#989898', font=roboto_data3, anchor='ms') # ayer, casos con sintomas\n",
    "txt.text((540, 680), '{}%'.format(procesovacunacion_hoy), fill='#dfdede', font=coolvetica_data2, anchor='ms') # casos sin sintomas\n",
    "txt.text((540, 750), 'Ayer: {}%'.format(procesovacunacion_ayer), fill='#989898', font=roboto_data3, anchor='ms') # ayer, casos sin sintomas\n",
    "txt.text((890, 680), '{}'.format(me_hoy), fill='#dfdede', font=coolvetica_data2, anchor='ms') # casos por laboratorio\n",
    "txt.text((890, 750), 'Ayer: {}'.format(me_ayer), fill='#989898', font=roboto_data3, anchor='ms') # ayer, casos por laboratorio\n",
    "txt.text((540, 860), 'Acum. 2° dosis: {}'.format(procesovacunaciontotales_hoy), fill='#989898', font=roboto_data1, anchor='ms') # nuevos antigeno\n",
    "\n",
    "### Guardamos\n",
    "diario5.save('../../out/diario/5.png')\n",
    "\n",
    "### Manipulando sexta imagen\n",
    "txt = ImageDraw.Draw(diario6)\n",
    "\n",
    "### Textos\n",
    "txt.text((780, 70), '{}'.format(tasanuevos_hoy), fill='#dfdede', font=coolvetica_data2) # casos con sintomas\n",
    "txt.text((280, 680), '{}'.format(activosprobables_hoy), fill='#dfdede', font=coolvetica_data2, anchor='ms') # casos con sintomas\n",
    "txt.text((280, 750), 'Ayer: {}'.format(activosprobables_ayer), fill='#989898', font=roboto_data3, anchor='ms') # ayer, casos con sintomas\n",
    "txt.text((800, 680), '{}%'.format(uciaprox_hoy), fill='#dfdede', font=coolvetica_data2, anchor='ms') # casos sin sintomas\n",
    "txt.text((800, 750), 'Error aprox.: ±{}%'.format(errorabs_hoy), fill='#989898', font=roboto_data3, anchor='ms') # ayer, casos sin sintomas\n",
    "\n",
    "### Guardamos\n",
    "diario6.save('../../out/diario/6.png')\n",
    "\n",
    "### Manipulando séptima, octava, novena y décima imagen\n",
    "x = range(7, 11)\n",
    "for i in x:\n",
    "    ### Gráficos\n",
    "    exec('diario{}.paste(graph{}, (-55, 155), graph{})'.format(i, i-4, i-4))\n",
    "    ### Guardamos\n",
    "    exec('diario{}.save(\"../../out/diario/{}.png\")'.format(i, i))\n",
    "    i += i\n",
    "    \n",
    "### ¿Todo ok?\n",
    "display(Markdown('> Todas las imágenes del reporte diario han sido correctamente exportadas.'))\n",
    "\n",
    "### Guardamos a PDF\n",
    "pdfs = []\n",
    "for i in range(2, 11):\n",
    "    exec('pdfs += [diario{}]'.format(i))\n",
    "\n",
    "### Histórico\n",
    "diario1.convert('RGB').save('../../out/diario/pdf/{}.pdf'.format(df['Casos nuevos'].last_valid_index().strftime('%Y.%m.%d'),\n",
    "                                                 df['Casos nuevos'].last_valid_index().strftime('%Y.%m.%d')\n",
    "                                             ), save_all=True, append_images=[pdf.convert('RGB') for pdf in pdfs])\n",
    "\n",
    "### Última actualización\n",
    "diario1.convert('RGB').save('../../out/diario/pdf/ult/ult.pdf', save_all=True, append_images=[pdf.convert('RGB') for pdf in pdfs])\n",
    "\n",
    "### ¿Todo ok?\n",
    "display(Markdown('> El PDF del reporte diario ha sido exportado.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance de vacunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generando balance de vacunas ###\n",
    "\n",
    "### Abriendo gráficos guardados\n",
    "x = range(1, 6)\n",
    "for i in x:\n",
    "    image_path = '../../in/vacuna/grafico/{}.png'.format(i)\n",
    "    exec('graph{} = Image.open(image_path)'.format(i))\n",
    "    i += i\n",
    "\n",
    "### Cargando imagenes\n",
    "for i in x:\n",
    "    image_path = '../../in/vacuna/{}.png'.format(i)\n",
    "    exec('vacuna{} = Image.open(image_path)'.format(i))\n",
    "    exec('vacuna{} = vacuna{}.copy()'.format(i, i))\n",
    "    i += i\n",
    "\n",
    "### Manipulando primera, segunda, tercera y cuarta imagen\n",
    "for i in x:\n",
    "    ### Gráficos\n",
    "    if i == 1:\n",
    "        txt = ImageDraw.Draw(vacuna1)\n",
    "        txt.text((860, 35), '{}° ed.'.format(ed_vacuna), fill='#b9b9b9', font=roboto_ed) # edicion\n",
    "        txt.text((380, 357), '{}'.format(df.loc[weekend_data].name.strftime('%d/%m/%Y')), fill='#fff', font=roboto_data1) # fecha\n",
    "        txt.text((610, 500), '{}'.format('{}%'.format(procesovacunacion_hoy)), fill='#9ad5ff', font=coolvetica_data4) # avance\n",
    "        txt.text((420, 670), 'Con esquema de vacunación', fill='white', font=roboto_data3) # texto1\n",
    "        txt.text((420, 710), 'completo (2° o única dosis)', fill='white', font=roboto_data3) # texto2\n",
    "        txt.text((380, 800), '{}'.format(format(int(vacunacion_pct['Población objetivo'][-1]), ',d')), fill='gray', font=coolvetica_data4) #restante\n",
    "        txt.text((420, 990), 'Personas deben iniciar o', fill='white', font=roboto_data3) #texto3\n",
    "        txt.text((420, 1030), 'completar su vacunación', fill='white', font=roboto_data3) #texto4\n",
    "        exec('vacuna{}.paste(graph{}, (100, 410), graph{})'.format(i, i, i))\n",
    "    elif i == 2 or i == 3:\n",
    "        exec('vacuna{}.paste(graph{}, (50, 250), graph{})'.format(i, i, i))\n",
    "    else:\n",
    "        exec('vacuna{}.paste(graph{}, (60, 240), graph{})'.format(i, i, i))\n",
    "    ### Guardamos\n",
    "    exec('vacuna{}.save(\"../../out/vacuna/{}.png\")'.format(i, i))\n",
    "    i += i\n",
    "\n",
    "### ¿Todo ok?\n",
    "display(Markdown('> Todas las imágenes del balance de vacunas han sido correctamente exportadas.'))\n",
    "\n",
    "### Guardamos a PDF\n",
    "pdfs = []\n",
    "for i in range(2, 6):\n",
    "    exec('pdfs += [vacuna{}]'.format(i))\n",
    "\n",
    "### Histórico    \n",
    "vacuna1.convert('RGB').save('../../out/vacuna/pdf/{}.pdf'.format(df['Casos nuevos'].last_valid_index().strftime('%Y.%m.%d')\n",
    "                                             ), save_all=True, append_images=[pdf.convert('RGB') for pdf in pdfs])\n",
    "\n",
    "### Última actualización\n",
    "vacuna1.convert('RGB').save('../../out/vacuna/pdf/ult/ult.pdf', save_all=True, append_images=[pdf.convert('RGB') for pdf in pdfs])\n",
    "\n",
    "### ¿Todo ok?\n",
    "display(Markdown('> El PDF del balance de vacunas ha sido exportado.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indicador de fase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Indicador de fase ###\n",
    "\n",
    "### Abriendo gráficos guardados\n",
    "x = range(1, 8)\n",
    "for i in x:\n",
    "    image_path = '../../in/indicadorfase/grafico/{}.png'.format(i)\n",
    "    exec('graph{} = Image.open(image_path)'.format(i))\n",
    "    i += i\n",
    "\n",
    "### Cargando imagenes\n",
    "x = range(1, 10)\n",
    "for i in x:\n",
    "    image_path = '../../in/indicadorfase/{}.png'.format(i)\n",
    "    exec('indicadorfase{} = Image.open(image_path)'.format(i))\n",
    "    exec('indicadorfase{} = indicadorfase{}.copy()'.format(i, i))\n",
    "    i += i\n",
    "\n",
    "### Manipulando primera, segunda, tercera y cuarta imagen\n",
    "\n",
    "### Para ir arreglando alto\n",
    "b = 0\n",
    "\n",
    "### Para tener índice de vector de colores\n",
    "co = 0\n",
    "\n",
    "for i in x:\n",
    "    ### Gráficos\n",
    "    if i == 1:\n",
    "        txt = ImageDraw.Draw(indicadorfase1)\n",
    "        txt.text((860, 35), '{}° ed.'.format(ed_indicador), fill='#b9b9b9', font=roboto_ed) # edicion\n",
    "        txt.text((360, 380), '{}'.format(df['Casos acumulados en Iquique'].last_valid_index().strftime('%d/%m/%Y')), fill='#fff', font=roboto_data1) # fecha\n",
    "        for val in resultado_prediccion:\n",
    "            txt.text((490, 512 + b), '{} '.format(str(int(resultado_prob[co].round(0))) + '%'), fill='#fff', font=roboto_data3) # prob\n",
    "            txt.text((670, 512 + b), '{}'.format(val), fill=resultado_colores[co], font=roboto_data3) # resultado\n",
    "            b += 72\n",
    "            co += 1\n",
    "    elif i == 2:\n",
    "        pass\n",
    "    else:\n",
    "        exec('indicadorfase{}.paste(graph{}, (60, 250), graph{})'.format(i, i-2, i-2))\n",
    "    ### Guardamos\n",
    "    exec('indicadorfase{}.save(\"../../out/indicadorfase/{}.png\")'.format(i, i))\n",
    "    i += i\n",
    "\n",
    "### ¿Todo ok?\n",
    "display(Markdown('> Todas las imágenes del indicador de fase han sido correctamente exportadas.'))\n",
    "\n",
    "### Guardamos a PDF\n",
    "pdfs = []\n",
    "for i in range(2, 10):\n",
    "    exec('pdfs += [indicadorfase{}]'.format(i))\n",
    "    \n",
    "### Histórico\n",
    "indicadorfase1.convert('RGB').save('../../out/indicadorfase/pdf/{}.pdf'.format(df['Casos acumulados en Alto Hospicio'].last_valid_index().strftime('%Y.%m.%d')\n",
    "                                             ), save_all=True, append_images=[pdf.convert('RGB') for pdf in pdfs])\n",
    "\n",
    "### Última actualización\n",
    "indicadorfase1.convert('RGB').save('../../out/indicadorfase/pdf/ult/ult.pdf', save_all=True, append_images=[pdf.convert('RGB') for pdf in pdfs])\n",
    "\n",
    "### ¿Todo ok?\n",
    "display(Markdown('> El PDF del indicador de fase ha sido exportado.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toque de queda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Indicador de fase ###\n",
    "\n",
    "### Abriendo gráficos guardados\n",
    "x = range(1, 3)\n",
    "for i in x:\n",
    "    image_path = '../../in/toquequeda/grafico/{}.png'.format(i)\n",
    "    exec('graph{} = Image.open(image_path)'.format(i))\n",
    "    i += i\n",
    "\n",
    "### Cargando imagenes\n",
    "x = range(1, 3)\n",
    "for i in x:\n",
    "    image_path = '../../in/toquequeda/{}.png'.format(i)\n",
    "    exec('toquequeda{} = Image.open(image_path)'.format(i))\n",
    "    exec('toquequeda{} = toquequeda{}.copy()'.format(i, i))\n",
    "    i += i\n",
    "\n",
    "### Manipulando primera, segunda, tercera y cuarta imagen\n",
    "\n",
    "### Para ir arreglando alto\n",
    "b = 0\n",
    "\n",
    "### Para tener índice de vector de colores\n",
    "co = 0\n",
    "\n",
    "for i in x:\n",
    "    exec('toquequeda{}.paste(graph{}, (-50, 100), graph{})'.format(i, i, i))\n",
    "    exec('toquequeda{}.save(\"../../out/toquequeda/{}.png\")'.format(i, i))\n",
    "\n",
    "### ¿Todo ok?\n",
    "display(Markdown('> Todas las imágenes del reporte del toque de queda han sido correctamente exportadas.'))\n",
    "\n",
    "### Guardamos a PDF\n",
    "pdfs = []\n",
    "for i in range(2, 3):\n",
    "    exec('pdfs += [toquequeda{}]'.format(i))\n",
    "    \n",
    "### Histórico\n",
    "toquequeda1.convert('RGB').save('../../out/toquequeda/pdf/{}.pdf'.format(df['Tasa de activos (incidencia) *'].last_valid_index().strftime('%Y.%m.%d')\n",
    "                                             ), save_all=True, append_images=[pdf.convert('RGB') for pdf in pdfs])\n",
    "\n",
    "### Última actualización\n",
    "toquequeda1.convert('RGB').save('../../out/toquequeda/pdf/ult/ult.pdf', save_all=True, append_images=[pdf.convert('RGB') for pdf in pdfs])\n",
    "\n",
    "### ¿Todo ok?\n",
    "display(Markdown('> El PDF del reporte de toque de queda ha sido exportado.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultado\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reporte diario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Mostramos las imágenes del reporte diario\n",
    "x = range(1, 11)\n",
    "for i in x:\n",
    "    exec('diario{} = Image.open(\"../../out/diario/{}.png\")'.format(i, i))\n",
    "    exec('display(diario{})'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance vacunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Mostramos las imágenes del balance de vacunas\n",
    "x = range(1, 6)\n",
    "for i in x:\n",
    "    exec('diario{} = Image.open(\"../../out/vacuna/{}.png\")'.format(i, i))\n",
    "    exec('display(vacuna{})'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indicador de fase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Mostramos las imágenes del indicador de fase\n",
    "x = range(1, 10)\n",
    "for i in x:\n",
    "    exec('diario{} = Image.open(\"../../out/indicadorfase/{}.png\")'.format(i, i))\n",
    "    exec('display(indicadorfase{})'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toque de queda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Mostramos las imágenes del indicador de fase\n",
    "x = range(1, 3)\n",
    "for i in x:\n",
    "    exec('toquequeda{} = Image.open(\"../../out/toquequeda/{}.png\")'.format(i, i))\n",
    "    exec('display(toquequeda{})'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplos\n",
    "\n",
    "La presente sección recopila los ejemplos mencionados en el notebook. Están recopilados a fin de fácil entendimiento (o al menos, en intento de)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(ejemplo1)=\n",
    "### Ejemplo (1)\n",
    "\n",
    "¿Cómo se ve un archivo .CSV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ejemplo 1 ###\n",
    "\n",
    "csv = \"\"\"\n",
    "\n",
    "Nombre,Apellido,Universidad\n",
    "Juan,Ponce,uchile\n",
    "Ermógenes,Pérez,usch\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "### Lo leemos con Pandas\n",
    "pd.read_csv(StringIO(csv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(ejemplo2)=\n",
    "### Ejemplo (2)\n",
    "\n",
    "¿Cuál es la media de error de la aproximación UCI?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ejemplo 2 ###\n",
    "### Para media móvil semanal, solo seleccionamos el último dato\n",
    "print('La media móvil del error de la última semana es de: ', df['UCI error abs *'][df['UCI error abs *'].last_valid_index()], '%')\n",
    "### Para la media general, promediamos todos los datos\n",
    "print('La media general del error es de: ', round(df['UCI error abs *'].mean(), 2), '%')\n",
    "\n",
    "### ¿En qué se traduce el error? En las distancias entre ambas curvas\n",
    "plt.plot(df.index[df['UCI ocupacion media movil aprox *'] != 0], \\\n",
    "         df['UCI ocupacion media movil aprox *'][df['UCI ocupacion media movil aprox *'] != 0], label='aproximación')\n",
    "plt.plot(df.index[df['UCI ocupacion media movil real'] != 0], \\\n",
    "         df['UCI ocupacion media movil real'][df['UCI ocupacion media movil real'] != 0], color='r', label='real')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aclaraciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Con relación a conceptos del Ministerio de Salud\n",
    "\n",
    "(1_aclaracion)=\n",
    "#### Casos activos confirmados\n",
    "\n",
    "**¿Por qué los casos activos confirmados del reporte diario del Minsal no calzan con los del reporte epidemiológico?** Ésto se debe a que, el reporte diario del Minsal:\n",
    "\n",
    "- No contempla en la suma de activos confirmados, a los activos probables {footcite}``b51-536``, en el reporte diario del Ministerio de Salud.\n",
    "\n",
    "(2_aclaracion)=\n",
    "#### Casos confirmados acumulados\n",
    "\n",
    "**¿Por qué los casos confirmados acumulados del reporte diario del Minsal no calzan con el total del reporte epidemiológico?** Ésto se debe a dos situaciones con respecto al reporte diario del Minsal:\n",
    "\n",
    "- No se contemplan casos probables {footcite}``b51-536``, en la suma de casos totales, en el reporte diario del Ministerio de Salud.\n",
    "\n",
    "<br>\n",
    "\n",
    "- No se contemplan casos notificados por laboratorio {footcite}``epi-04-06-2021``, en la suma total, en el reporte diario del Ministerio de Salud.\n",
    "\n",
    "Ésto implica que:\n",
    "\n",
    "$$ \n",
    "\\begin{align}\n",
    "\\Large TOTAL = casos_{confirmados \\ notificados} + casos_{probables} + casos_{notificados \\ laboratorio}\n",
    "\\end{align}\n",
    "$$ (casos_epidemiologico)\n",
    "\n",
    "#### Definiciones\n",
    "\n",
    "Respecto a las definiciones de la nomenclatura:\n",
    "\n",
    "- Los casos probables, por definición {footcite}``b51-536``, \"<i>Persona que cumple con la definición de caso sospechoso y tiene un resultado indeterminado o no concluyente de la RT-PCR, o persona asintomática o con un síntoma no cardinal, que tiene un resultado positivo para una prueba de detección rápida de antígenos para SARS-CoV-2, o bien, persona que cumple con la definición de caso sospechoso en el cual el resultado de la RT-PCR es negativo o indeterminado o no concluyente, pero que tiene una tomografía computarizada de tórax con imágenes sugerentes de COVID-19</i>\" según {cite}``b51-536``.\n",
    "\n",
    "<br>\n",
    "\n",
    "- Los casos notificados por laboratorio, por definición {footcite}``epi-04-06-2021``, \"<i>Persona que tiene un resultado de RT-PCR positivo para SARS-CoV-2 pero que no está registrada en la plataforma EPIVIGILA</i>\" según {cite}``epi-04-06-2021``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requerimientos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviar esta celda. Está hecha para que el action [actualiza_libro](https://github.com/pandemiaventana/pandemiaventana/actions/workflows/book.yml) funcione correctamente según librerías utilizadas en el Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Gracias a Alex P. Miller (https://stackoverflow.com/a/49199019/13746427) ###\n",
    "def get_imports():\n",
    "    for name, val in globals().items():\n",
    "        if isinstance(val, types.ModuleType):\n",
    "            # Split ensures you get root package, \n",
    "            # not just imported function\n",
    "            name = val.__name__.split(\".\")[0]\n",
    "\n",
    "        elif isinstance(val, type):\n",
    "            name = val.__module__.split(\".\")[0]\n",
    "\n",
    "        # Some packages are weird and have different\n",
    "        # imported names vs. system/pip names. Unfortunately,\n",
    "        # there is no systematic way to get pip names from\n",
    "        # a package's imported name. You'll have to add\n",
    "        # exceptions to this list manually!\n",
    "        poorly_named_packages = {\n",
    "            \"PIL\": \"Pillow\",\n",
    "            \"sklearn\": \"scikit-learn\"\n",
    "        }\n",
    "        if name in poorly_named_packages.keys():\n",
    "            name = poorly_named_packages[name]\n",
    "\n",
    "        yield name\n",
    "imports = list(set(get_imports()))\n",
    "\n",
    "# The only way I found to get the version of the root package\n",
    "# from only the name of the package is to cross-check the names \n",
    "# of installed packages vs. imported packages\n",
    "requirements = []\n",
    "req = ''\n",
    "for m in pkg_resources.working_set:\n",
    "    if m.project_name in imports and m.project_name!=\"pip\":\n",
    "        requirements.append((m.project_name, m.version))\n",
    "        \n",
    "\n",
    "for r in requirements:\n",
    "    req += \"\"\"{}=={}\n",
    "\"\"\".format(*r)\n",
    "req += \"\"\"jupyter-book\n",
    "\"\"\" + \"\"\"session_info\n",
    "\"\"\" + \"\"\"markdownify\n",
    "\"\"\" + \"\"\"bs4\n",
    "\"\"\" + \"\"\"natsort\"\"\"\n",
    "\n",
    "### Abrimos y modificamos requirements.txt\n",
    "with open('../../requirements.txt', 'w') as f:\n",
    "    f.write(req)\n",
    "    # ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Información de sesión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "session_info.show(cpu=True, jupyter=True, std_lib=True, write_req_file=True, dependencies=True, req_file_name='1_requeriments.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliografía de esta página\n",
    "\n",
    "```{footbibliography}\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
